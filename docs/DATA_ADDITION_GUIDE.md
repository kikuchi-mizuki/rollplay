# RAGデータ追加ガイド

## 📊 現在のデータ状況

- **総件数**: 898件
- **ソース動画**: 11本
- **目標**: 1,500-2,000件（動画30-50本）

---

## 🎯 追加すべき動画の種類

### 優先度 高（精度向上に最も効果的）

1. **❌ 断り文句が多い面談**
   - 「予算が厳しい」「今は検討段階」「他社と比較中」
   - 難易度の高い顧客への対応パターンを学習

2. **🤔 質問が多い顧客**
   - 「具体的にどういう仕組み？」「他社との違いは？」
   - 詳細な説明が必要な場面の応答パターン

3. **💰 予算に厳しい顧客**
   - 「もっと安くならない？」「費用対効果は？」
   - コスト意識の高い顧客への対応

### 優先度 中（バリエーション向上）

4. **🏃 意思決定が早い顧客**
   - 「いいですね、始めましょう」「すぐ契約したい」
   - スムーズな商談の流れ

5. **🐢 慎重に検討する顧客**
   - 「もう少し考えさせてください」「社内で相談します」
   - 長期的な検討段階の対応

6. **🏢 業種・規模別のバリエーション**
   - 飲食店、美容サロン、アパレル、ECなど
   - 小規模（〜5名）、中規模（6-20名）、大規模（21名〜）

---

## 📁 ステップ1: 動画ファイルの準備

### 1-1. 動画ファイルの形式

**対応フォーマット**:
- ✅ MP4（推奨）
- ✅ MP3（音声のみ）
- ✅ WAV
- ✅ M4A

**推奨設定**:
- 音質: 44.1kHz以上
- ビットレート: 128kbps以上
- 時間: 10分〜60分程度

### 1-2. ファイル命名規則

シナリオIDをファイル名に含めてください：

```
<scenario_id>_<連番>_<任意の説明>.mp4
```

**例**:
```
meeting_1st_005_budget_concern.mp4    # 1次面談・予算懸念
meeting_1st_006_question_heavy.mp4    # 1次面談・質問多い
meeting_2nd_003_cautious_customer.mp4 # 2次面談・慎重な顧客
upsell_003_fast_decision.mp4          # アップセル・即決
```

**シナリオID一覧**:
- `meeting_1st` - 1次面談（初回商談）
- `meeting_1_5th` - 1.5次面談
- `meeting_2nd` - 2次面談
- `meeting_3rd` - 3次面談
- `kickoff` - キックオフミーティング
- `upsell` - アップセル営業

### 1-3. 動画の配置

動画ファイルを `transcripts/` ディレクトリに配置：

```bash
# macOSの場合
cp ~/Downloads/meeting_1st_005.mp4 /Users/kikuchimizuki/Desktop/04_池田さん_ロープレ/rollplay/transcripts/

# 複数ファイルを一括コピー
cp ~/Downloads/meeting_*.mp4 /Users/kikuchimizuki/Desktop/04_池田さん_ロープレ/rollplay/transcripts/
```

---

## 🎤 ステップ2: 文字起こし実行

### 2-1. 環境確認

```bash
cd /Users/kikuchimizuki/Desktop/04_池田さん_ロープレ/rollplay

# OpenAI APIキーが設定されているか確認
echo $OPENAI_API_KEY
```

### 2-2. 文字起こし実行

```bash
# 文字起こしツールを実行
python tools/transcribe_videos.py
```

**実行時の流れ**:
```
1. transcripts/ 内の動画ファイルを検索
2. まだ文字起こしされていないファイルを検出
3. Whisper API で文字起こし実行（1ファイル数分〜10分）
4. JSON形式で保存（例: meeting_1st_005_transcript.json）
```

**注意事項**:
- ⚠️ Whisper APIは有料（約$0.006/分）
- 10本の動画（各30分）= 約$1.8
- 処理時間: 1ファイル5-10分程度

### 2-3. 文字起こし結果の確認

```bash
# 文字起こしファイルが生成されているか確認
ls -lh transcripts/*_transcript.json

# 最新のファイルの中身を確認
cat transcripts/meeting_1st_005_transcript.json | jq '.segments | length'
```

---

## 🔧 ステップ3: RAGインデックスの再構築

### 3-1. RAGインデックス構築

```bash
# RAGインデックス構築ツールを実行
python tools/build_rag_index.py
```

**実行時の流れ**:
```
1. transcripts/ 内の全ての *_transcript.json を読み込み
2. 顧客発言を抽出
3. シーン判定（greeting/needs_analysis/proposal/closing）
4. OpenAI text-embedding-3-large でEmbedding生成
5. FAISSインデックスを構築
6. rag_index/ に保存
```

**処理時間と費用**:
- Embedding生成: 約$0.00013/1000トークン
- 1,000件の発言 ≈ $0.13
- 処理時間: 5-15分

### 3-2. インデックス構築結果の確認

```bash
# 構築されたインデックスの件数を確認
jq 'length' rag_index/sales_patterns.json

# シナリオ別の内訳を確認
jq -r 'group_by(.scenario_id) | map({scenario: .[0].scenario_id, count: length}) | .[] | "\(.scenario): \(.count)件"' rag_index/sales_patterns.json
```

**期待される結果**（動画5本追加の場合）:
```
RAGデータ件数: 1200-1300
meeting_1st: 450件
meeting_2nd: 150件
upsell: 280件
...
```

---

## 🚀 ステップ4: バックエンド再起動と効果確認

### 4-1. バックエンド再起動

```bash
# 既存のプロセスを停止（Ctrl+C）
# 新しいRAGインデックスを読み込んで起動
python3 app.py 5001
```

起動時のログで確認：
```
RAGインデックス読込完了: 1247件のパターン  ← 件数が増えていればOK
```

### 4-2. ブラウザリロード

ブラウザで `Cmd+Shift+R`（ハードリロード）

### 4-3. 効果確認

**コンソールログで確認**:
```
[RAG文脈強化] 検出トピック: 予算, 効果
[RAG採用] パターン1 (類似度距離: 0.234)
[RAG採用] パターン2 (類似度距離: 0.287)
...
[RAG除外] 類似度が低いパターンをスキップ（距離: 0.612）
```

**会話の質を確認**:
- ✅ より多様な応答パターン
- ✅ 状況に応じた適切な応答
- ✅ 同じ応答の繰り返しが減少

---

## 📊 データ量と精度の関係

| データ件数 | 動画本数 | 精度（推定） | 効果 |
|-----------|---------|------------|------|
| 898件（現在） | 11本 | ★★★☆☆ | ベースライン |
| 1,500件 | 30本 | ★★★★☆ | +20-30% |
| 2,000件 | 50本 | ★★★★★ | +30-40% |
| 3,000件 | 80本 | ★★★★★ | +40-50% |
| 5,000件+ | 100本+ | ★★★★★ | +50-60% |

---

## 🎯 推奨スケジュール

### フェーズ1（即座）: 高品質5-10本追加
- **目標**: 1,500件（+600件）
- **期間**: 1-2週間
- **費用**: 約$5-10（文字起こし+Embedding）
- **効果**: +20-30%精度向上

### フェーズ2（1ヶ月後）: 20-30本追加
- **目標**: 2,000-2,500件
- **期間**: 1ヶ月
- **費用**: 約$15-20
- **効果**: +30-40%精度向上

### フェーズ3（長期）: 50本以上
- **目標**: 3,000-5,000件
- **期間**: 2-3ヶ月
- **費用**: 約$30-50
- **効果**: +40-60%精度向上

---

## ⚠️ よくある問題と解決法

### Q1: 文字起こしでエラーが出る

```bash
# エラー例: "Audio file is too large"
# 解決: 動画を圧縮または分割

# ffmpegで圧縮（オーディオビットレート下げる）
ffmpeg -i input.mp4 -ab 128k output.mp4
```

### Q2: Embedding生成が遅い

```bash
# 1000件以上の場合、途中経過が表示される
# 待つだけでOK（5-15分）
# 処理が止まったように見えても続行中
```

### Q3: RAGインデックス読み込みエラー

```bash
# インデックスファイルを削除して再構築
rm -rf rag_index/
python tools/build_rag_index.py
```

### Q4: 精度が上がらない

**確認事項**:
1. 類似度閾値が厳しすぎないか（0.5→0.6に変更）
2. シナリオIDが正しく設定されているか
3. 動画の音質が十分か（ノイズが多いとNG）

---

## 📝 チェックリスト

### データ追加前
- [ ] 動画ファイルを準備（MP4/MP3）
- [ ] ファイル名にシナリオIDを含める
- [ ] transcripts/ ディレクトリに配置
- [ ] OpenAI APIキー確認

### 文字起こし後
- [ ] *_transcript.json が生成されている
- [ ] JSONファイルにsegmentsが含まれている
- [ ] 顧客発言（customer）が抽出されている

### RAG構築後
- [ ] rag_index/sales_patterns.faiss が更新されている
- [ ] rag_index/sales_patterns.json のlengthが増えている
- [ ] シナリオ別の件数が増えている

### 動作確認
- [ ] バックエンド再起動時にRAG件数が増えている
- [ ] ブラウザをハードリロード
- [ ] コンソールでRAG採用ログを確認
- [ ] 会話の質が向上している

---

## 🎉 完了！

データ追加が完了したら、以下を確認：

1. **ログで確認**
```bash
# バックエンド起動時
RAGインデックス読込完了: 1247件のパターン
```

2. **会話で確認**
   - より多様な応答
   - 状況に応じた適切な応答
   - リアルな口調とバリエーション

3. **次のステップ**
   - さらに動画を追加して精度向上
   - フィードバックを元に動画選定を最適化
