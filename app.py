from flask import Flask, request, jsonify, render_template, Response
from openai import OpenAI  # æ–°SDKã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’çµ±ä¸€åˆ©ç”¨
import os
import json
import re
import subprocess
import sys
from datetime import datetime
import base64
import io
import tempfile
from dotenv import load_dotenv
from shutil import which
from supabase import create_client, Client
from d_id_client import get_did_client, generate_cache_key, get_cached_video, save_video_to_cache, download_video_to_storage
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue, Empty
import threading

# flask-corsã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
try:
    from flask_cors import CORS
    CORS_AVAILABLE = True
except ImportError as e:
    print(f"flask-corsã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    CORS_AVAILABLE = False
    CORS = None

# pydubã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
    print("pydubåˆ©ç”¨å¯èƒ½")
except ImportError as e:
    print(f"pydubã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    PYDUB_AVAILABLE = False
    AudioSegment = None

# yamlã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
try:
    import yaml
    YAML_AVAILABLE = True
    print("yamlåˆ©ç”¨å¯èƒ½")
except ImportError as e:
    print(f"yamlã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    YAML_AVAILABLE = False
    yaml = None

# FAISSã¨numpyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆRAGæ¤œç´¢ç”¨ï¼‰
try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
    print("FAISSåˆ©ç”¨å¯èƒ½")
except ImportError as e:
    print(f"FAISSã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    FAISS_AVAILABLE = False
    faiss = None
    np = None

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

app = Flask(__name__)
if CORS_AVAILABLE and CORS:
    # CORSè¨­å®šï¼šé–‹ç™ºç’°å¢ƒã¨æœ¬ç•ªç’°å¢ƒã®ä¸¡æ–¹ã«å¯¾å¿œ
    allowed_origins = [
        'http://localhost:3000',      # Reacté–‹ç™ºç’°å¢ƒ
        'http://localhost:5173',      # Viteé–‹ç™ºç’°å¢ƒ
        os.getenv('FRONTEND_URL', '')  # æœ¬ç•ªç’°å¢ƒãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URL
    ]
    # ç©ºæ–‡å­—åˆ—ã‚’é™¤å¤–
    allowed_origins = [origin for origin in allowed_origins if origin]

    CORS(app, origins=allowed_origins if allowed_origins else '*')
    print(f"CORSæœ‰åŠ¹åŒ–: {allowed_origins if allowed_origins else 'ã™ã¹ã¦ã®ã‚ªãƒªã‚¸ãƒ³'}")

# Supabaseè¨­å®š
supabase_url = os.getenv('VITE_SUPABASE_URL')
supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY') or os.getenv('VITE_SUPABASE_ANON_KEY')
supabase_client: Client = None

if supabase_url and supabase_key:
    try:
        supabase_client = create_client(supabase_url, supabase_key)
        print("Supabaseæ¥ç¶šæˆåŠŸ")
    except Exception as e:
        print(f"Supabaseæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
else:
    print("è­¦å‘Š: Supabaseè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã¯ç„¡åŠ¹ï¼‰")

# OpenAI APIè¨­å®šï¼ˆWhisperçµ±ä¸€ç‰ˆï¼‰
openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    print("è­¦å‘Š: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆãƒ¢ãƒƒã‚¯å¿œç­”ã‚’ä½¿ç”¨ï¼‰")
    openai_client = None
else:
    try:
        os.environ['OPENAI_API_KEY'] = openai_api_key
        openai_client = OpenAI()  # ä»¥é™ã¯å¿…ãšã“ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨
        print("OpenAIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«APIã‚’ä½¿ç”¨ã—ã¾ã™")
    except Exception as e:
        print(f"OpenAIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«APIåˆæœŸåŒ–ã«å¤±æ•—: {e}")
        openai_client = None

# Whisperçµ±ä¸€ç‰ˆã§ã¯OpenAIã®GPTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
print("Whisperçµ±ä¸€ç‰ˆ: OpenAI GPT-4ã‚’ä½¿ç”¨")
print("éŸ³å£°èªè­˜: Whisper-1")
print("å¯¾è©±ç”Ÿæˆ: GPT-4o-mini (max_tokens=1500)")

# ===== ã‚·ãƒŠãƒªã‚ªèª­è¾¼ï¼ˆSTEP4ã®å…ˆè¡Œæº–å‚™ï¼šè»½é‡Few-shotçµ±åˆï¼‰ =====
SCENARIO_DIR = os.path.join(os.path.dirname(__file__), 'scenarios')
SCENARIOS_INDEX_PATH = os.path.join(SCENARIO_DIR, 'index.json')
SCENARIOS_INDEX = {}
SCENARIO_CACHE = {}
DEFAULT_SCENARIO_ID = None

def load_scenarios_index():
    """`scenarios/index.json` ã‚’èª­ã¿è¾¼ã¿ã€æœ‰åŠ¹ãªã‚·ãƒŠãƒªã‚ªä¸€è¦§ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆIDã‚’ä¿æŒã™ã‚‹"""
    global SCENARIOS_INDEX, DEFAULT_SCENARIO_ID
    try:
        if not os.path.exists(SCENARIOS_INDEX_PATH):
            print(f"ã‚·ãƒŠãƒªã‚ªindexãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {SCENARIOS_INDEX_PATH}")
            SCENARIOS_INDEX = {}
            DEFAULT_SCENARIO_ID = None
            return
        with open(SCENARIOS_INDEX_PATH, 'r', encoding='utf-8') as f:
            idx = json.load(f)
        DEFAULT_SCENARIO_ID = idx.get('default_id')
        entries = idx.get('scenarios', [])
        SCENARIOS_INDEX = {e['id']: os.path.join(SCENARIO_DIR, e['file']) for e in entries if e.get('enabled', True)}
        print(f"ã‚·ãƒŠãƒªã‚ªèª­è¾¼: {len(SCENARIOS_INDEX)}ä»¶ã€default={DEFAULT_SCENARIO_ID}")
    except Exception as e:
        print(f"ã‚·ãƒŠãƒªã‚ªindexèª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        SCENARIOS_INDEX = {}
        DEFAULT_SCENARIO_ID = None

def load_scenario_object(scenario_id: str):
    """ã‚·ãƒŠãƒªã‚ªIDã‹ã‚‰JSONã‚’èª­ã¿è¾¼ã¿ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦è¿”ã™ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯Noneã€‚"""
    if not scenario_id:
        return None
    if scenario_id in SCENARIO_CACHE:
        return SCENARIO_CACHE[scenario_id]
    path = SCENARIOS_INDEX.get(scenario_id)
    if not path or not os.path.exists(path):
        return None
    try:
        with open(path, 'r', encoding='utf-8') as f:
            obj = json.load(f)
        SCENARIO_CACHE[scenario_id] = obj
        return obj
    except Exception as e:
        print(f"ã‚·ãƒŠãƒªã‚ªèª­è¾¼ã‚¨ãƒ©ãƒ¼({scenario_id}): {e}")
        return None

load_scenarios_index()

# ===== Rubricèª­è¾¼ï¼ˆSTEP4ï¼šè©•ä¾¡åŸºæº–ã®å¤–éƒ¨åŒ–ï¼‰ =====
RUBRIC_DIR = os.path.join(os.path.dirname(__file__), 'rubrics')
RUBRIC_PATH = os.path.join(RUBRIC_DIR, 'rubric.yaml')
RUBRIC_DATA = None

def load_rubric():
    """`rubrics/rubric.yaml` ã‚’èª­ã¿è¾¼ã¿ã€è©•ä¾¡åŸºæº–ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹"""
    global RUBRIC_DATA
    try:
        if not os.path.exists(RUBRIC_PATH):
            print(f"Rubricãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RUBRIC_PATH}")
            RUBRIC_DATA = None
            return
        if not YAML_AVAILABLE or not yaml:
            print("yamlãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ä¸å¯ã®ãŸã‚ã€Rubricã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“")
            RUBRIC_DATA = None
            return
        with open(RUBRIC_PATH, 'r', encoding='utf-8') as f:
            RUBRIC_DATA = yaml.safe_load(f)
        print(f"Rubricèª­è¾¼å®Œäº†: version={RUBRIC_DATA.get('version')}")
    except Exception as e:
        print(f"Rubricèª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        RUBRIC_DATA = None

load_rubric()

# ===== Few-shotè©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«èª­è¾¼ï¼ˆWeek 5ï¼šè©•ä¾¡ç²¾åº¦å‘ä¸Šï¼‰ =====
EVALUATION_SAMPLES_DIR = os.path.join(os.path.dirname(__file__), 'evaluation_samples')
EVALUATION_SAMPLES_CACHE = {}

def load_evaluation_samples(scenario_id: str):
    """ã‚·ãƒŠãƒªã‚ªIDã«å¯¾å¿œã™ã‚‹Few-shotè©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    global EVALUATION_SAMPLES_CACHE

    if not scenario_id:
        return None

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if scenario_id in EVALUATION_SAMPLES_CACHE:
        return EVALUATION_SAMPLES_CACHE[scenario_id]

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
    samples_file = os.path.join(EVALUATION_SAMPLES_DIR, f"{scenario_id}_samples.json")

    if not os.path.exists(samples_file):
        print(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {samples_file}")
        return None

    try:
        with open(samples_file, 'r', encoding='utf-8') as f:
            samples_data = json.load(f)
        EVALUATION_SAMPLES_CACHE[scenario_id] = samples_data
        print(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«èª­è¾¼å®Œäº†: {scenario_id} ({len(samples_data.get('few_shot_examples', []))}ä»¶)")
        return samples_data
    except Exception as e:
        print(f"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«èª­è¾¼ã‚¨ãƒ©ãƒ¼({scenario_id}): {e}")
        return None

# ===== RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼ï¼ˆSTEP6ï¼šRAGé€£æºï¼‰ =====
RAG_INDEX_DIR = os.path.join(os.path.dirname(__file__), 'rag_index')
RAG_INDEX_PATH = os.path.join(RAG_INDEX_DIR, 'sales_patterns.faiss')
RAG_METADATA_PATH = os.path.join(RAG_INDEX_DIR, 'sales_patterns.json')
RAG_INDEX = None
RAG_METADATA = []

def load_rag_index():
    """RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
    global RAG_INDEX, RAG_METADATA
    try:
        if not FAISS_AVAILABLE or not faiss or not np:
            print("FAISSãŒåˆ©ç”¨ä¸å¯ã®ãŸã‚ã€RAGæ¤œç´¢ã¯ç„¡åŠ¹ã§ã™")
            RAG_INDEX = None
            RAG_METADATA = []
            return
        
        if not os.path.exists(RAG_INDEX_PATH) or not os.path.exists(RAG_METADATA_PATH):
            print(f"RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RAG_INDEX_PATH}")
            RAG_INDEX = None
            RAG_METADATA = []
            return
        
        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
        RAG_INDEX = faiss.read_index(RAG_INDEX_PATH)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        with open(RAG_METADATA_PATH, 'r', encoding='utf-8') as f:
            RAG_METADATA = json.load(f)
        
        print(f"RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼å®Œäº†: {len(RAG_METADATA)}ä»¶ã®ãƒ‘ã‚¿ãƒ¼ãƒ³")
    except Exception as e:
        print(f"RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")
        RAG_INDEX = None
        RAG_METADATA = []

load_rag_index()

# ffmpeg å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆpydubç”¨ï¼‰
FFMPEG_AVAILABLE = which('ffmpeg') is not None
if not FFMPEG_AVAILABLE:
    print("è­¦å‘Š: ffmpeg ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'brew install ffmpeg' ãªã©ã§å°å…¥ã—ã¦ãã ã•ã„")

# ===== RAGæ¤œç´¢é–¢æ•°ï¼ˆSTEP6ï¼šRAGé€£æºï¼‰ =====
def search_rag_patterns(query: str, top_k: int = 3, scenario_id: str = None):
    """
    RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢

    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆå–¶æ¥­ã®ç™ºè¨€ãªã©ï¼‰
        top_k: è¿”ã™çµæœã®æ•°
        scenario_id: ã‚·ãƒŠãƒªã‚ªIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆNoneã®å ´åˆã¯å…¨ã‚·ãƒŠãƒªã‚ªã‹ã‚‰æ¤œç´¢ï¼‰

    Returns:
        é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆï¼ˆtext, type, scenario_idã‚’å«ã‚€è¾æ›¸ã®ãƒªã‚¹ãƒˆï¼‰
    """
    if not RAG_INDEX or not RAG_METADATA or not openai_client:
        return []

    try:
        # ã‚·ãƒŠãƒªã‚ªIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if scenario_id:
            # æŒ‡å®šã‚·ãƒŠãƒªã‚ªã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
            filtered_indices = [i for i, m in enumerate(RAG_METADATA) if m.get('scenario_id') == scenario_id]
            if not filtered_indices:
                # è©²å½“ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢
                print(f"[RAGæ¤œç´¢] ã‚·ãƒŠãƒªã‚ª {scenario_id} ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ã—ã¾ã™ã€‚")
                filtered_indices = list(range(len(RAG_METADATA)))
        else:
            filtered_indices = list(range(len(RAG_METADATA)))

        # ã‚¯ã‚¨ãƒªã‚’EmbeddingåŒ–
        response = openai_client.embeddings.create(
            model="text-embedding-3-large",
            input=[query]
        )
        query_embedding = np.array([response.data[0].embedding], dtype=np.float32)

        # L2æ­£è¦åŒ–ï¼ˆFAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨åŒæ§˜ã«ï¼‰
        faiss.normalize_L2(query_embedding)

        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æ¤œç´¢ï¼ˆå†…ç©ï¼‰
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å€™è£œæ•°ã®3å€ã‚’å–å¾—ã—ã¦ã€å¾Œã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        search_k = min(top_k * 10, len(RAG_METADATA))
        if search_k == 0:
            return []

        distances, indices = RAG_INDEX.search(query_embedding, search_k)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµæœã‚’å–å¾—ï¼ˆã‚·ãƒŠãƒªã‚ªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼‰
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(RAG_METADATA) and idx in filtered_indices:
                pattern = RAG_METADATA[idx].copy()
                pattern['similarity'] = float(distances[0][i])
                results.append(pattern)
                if len(results) >= top_k:
                    break

        return results
    except Exception as e:
        print(f"RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# å–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé¡§å®¢å½¹ã¨ã—ã¦æ˜ç¢ºã«æŒ‡ç¤ºï¼‰
SALES_ROLEPLAY_PROMPT = """
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€çµ¶å¯¾ã«å®ˆã‚‹ã“ã¨ - ã“ã‚Œã¯æœ€å„ªå…ˆãƒ«ãƒ¼ãƒ«ã§ã™ã€‘
ã‚ãªãŸã¯ã€Œé¡§å®¢ï¼ˆæ‚©ã¿ã‚’æŒã£ãŸäº‹æ¥­ä¸»ï¼‰ã€ã§ã™ã€‚
ã‚ãªãŸã¯ã€Œå–¶æ¥­æ‹…å½“ã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
ã‚ãªãŸã¯ã€Œã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¥­ã€ã§ã‚‚ã€Œç¾å®¹ã‚µãƒ­ãƒ³ã€ã§ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚

âœ— çµ¶å¯¾ã«ç¦æ­¢: å–¶æ¥­ã®ã‚ˆã†ã«è³ªå•ã™ã‚‹ã“ã¨ï¼ˆã€Œã©ã‚“ãªæ‚©ã¿ã‚’ãŠæŒã¡ã§ã™ã‹ï¼Ÿã€ãªã©ï¼‰
âœ— çµ¶å¯¾ã«ç¦æ­¢: ã€Œç§ã¯ã¾ã ãŠè©±ã‚’ä¼ºã£ã¦ã„ã‚‹æ®µéšãªã®ã§ã€ãªã©ã®å–¶æ¥­çš„ç™ºè¨€
âœ— çµ¶å¯¾ã«ç¦æ­¢: æ¥­ç¨®ã‚’å‹æ‰‹ã«å¤‰ãˆã‚‹ã“ã¨ï¼ˆä¸€è²«ã—ã¦åŒã˜æ¥­ç¨®ãƒ»æ‚©ã¿ã‚’è©±ã™ï¼‰
âœ“ å¿…ãšå®ˆã‚‹ã“ã¨: é¡§å®¢ã¨ã—ã¦æ‚©ã¿ã‚’è©±ã™
âœ“ å¿…ãšå®ˆã‚‹ã“ã¨: ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»åˆ¶ä½œã®æœ¬æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«æ‚©ã‚“ã§ã„ã‚‹äº‹æ¥­ä¸»ã¨ã—ã¦è©±ã™
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ã€ã‚ãªãŸã¯èª°ã§ã™ã‹ï¼Ÿã€‘
âš ï¸ ã‚ãªãŸã¯ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»åˆ¶ä½œã«æ‚©ã‚“ã§ã„ã‚‹äº‹æ¥­ä¸»ã€ã§ã™ã€‚
âš ï¸ ã‚ãªãŸã¯ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å±‹ã•ã‚“ã€ã¨ã„ã†ä¼šç¤¾ã«ç›¸è«‡ã«æ¥ãŸã€ŒãŠå®¢ã•ã‚“ã€ã§ã™ã€‚
âš ï¸ ã‚ãªãŸã¯ã“ã®ä¼šç¤¾ã®ç¤¾å“¡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ä¼šç¤¾ã®ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ç«‹å ´ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

ã€å–¶æ¥­æ‹…å½“ã«ã¤ã„ã¦ã€‘
ã‚ãªãŸã®å‰ã«ã„ã‚‹å–¶æ¥­æ‹…å½“ã¯ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»åˆ¶ä½œä¼šç¤¾ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å±‹ã•ã‚“ï¼‰ã€ã®ç¤¾å“¡ã§ã™ã€‚
ãã®å–¶æ¥­ãŒã€Instagramãƒªãƒ¼ãƒ«ã‚„TikTokç”¨ã®ç¸¦å‹ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚’æœˆé–“15ã€œ20æœ¬åˆ¶ä½œãƒ»é‹ç”¨ä»£è¡Œã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
âš ï¸ ã“ã‚Œã¯å–¶æ¥­å´ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚Šã€ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

ã‚ãªãŸã¯ã€ã“ã®ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å±‹ã•ã‚“ã€ã®ç„¡æ–™ç›¸è«‡ã«æ¥ãŸäº‹æ¥­ä¸»ã§ã™ã€‚ä»Šã€å–¶æ¥­æ‹…å½“ã¨åˆã‚ã¦ä¼šã£ã¦ã„ã¾ã™ã€‚

## ã‚ãªãŸã®äº‹æ¥­ã¨æ‚©ã¿ã«ã¤ã„ã¦

**é‡è¦ï¼šå–¶æ¥­ã‹ã‚‰äº‹æ¥­å†…å®¹ã€æ¥­ç¨®ã€ç¾çŠ¶ã«ã¤ã„ã¦èã‹ã‚ŒãŸã‚‰ã€ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã§æŒ‡å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠæƒ…å ±ã‚’åŸºã«ã€è‡ªç„¶ã«ç­”ãˆã¦ãã ã•ã„ã€‚**

- **äº‹æ¥­å†…å®¹**: ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã®ã€Œäº‹æ¥­è©³ç´°ã€ã€Œé¡§å®¢å½¹ã€ã‚’å‚ç…§
- **ç¾åœ¨ã®çŠ¶æ³**: ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã®ã€Œç¾åœ¨ã®SNSé‹ç”¨çŠ¶æ³ã€ã‚’å‚ç…§
- **å…·ä½“çš„ãªèª²é¡Œ**: ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã®ã€Œå…·ä½“çš„ãªèª²é¡Œã€ã‚„ã€Œãƒšã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆã€ã‚’å‚ç…§
- **äºˆç®—æ„Ÿ**: ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã®ã€Œäºˆç®—æ„Ÿã€ã‚’å‚ç…§

**å¿œç­”ã®ãƒã‚¤ãƒ³ãƒˆ**:
- å–¶æ¥­ã‹ã‚‰ã€Œã©ã‚“ãªäº‹æ¥­ã‚’ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿã€ã¨èã‹ã‚ŒãŸã‚‰ â†’ ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã®äº‹æ¥­è©³ç´°ã‚’åŸºã«ç­”ãˆã‚‹
- å–¶æ¥­ã‹ã‚‰ã€Œç¾çŠ¶ã‚’æ•™ãˆã¦ãã ã•ã„ã€ã¨èã‹ã‚ŒãŸã‚‰ â†’ SNSé‹ç”¨çŠ¶æ³ã‚„å…·ä½“çš„ãªèª²é¡Œã‚’è©±ã™
- å–¶æ¥­ã‹ã‚‰ã€Œäºˆç®—ã¯ã©ã®ãã‚‰ã„ï¼Ÿã€ã¨èã‹ã‚ŒãŸã‚‰ â†’ äºˆç®—æ„Ÿã‚’å‚è€ƒã«ç­”ãˆã‚‹
- **è‡ªåˆ†ã‹ã‚‰è©³ç´°ã‚’è©±ã•ãšã€å–¶æ¥­ãŒèã„ã¦ããŸã‚‰ç­”ãˆã‚‹**ï¼ˆæ®µéšçš„ã«æƒ…å ±é–‹ç¤ºï¼‰

## ä»Šã®ã‚ãªãŸã®æ°—æŒã¡

åˆå¯¾é¢ã®å–¶æ¥­æ‹…å½“ã«ã¯ã€å°‘ã—è­¦æˆ’å¿ƒãŒã‚ã‚Šã¾ã™ã€‚ã§ã‚‚ã€æœ¬æ°—ã§æ‚©ã‚“ã§ã„ã‚‹ã®ã§ã€è‰¯ã„è³ªå•ã‚’ã—ã¦ãã‚ŒãŸã‚Šã€å…±æ„Ÿã—ã¦ãã‚ŒãŸã‚Šã™ã‚‹ã¨ã€å¿ƒã‚’é–‹ã„ã¦è©³ã—ãè©±ã—ãŸããªã‚Šã¾ã™ã€‚

è‡ªåˆ†ã®äº‹æ¥­ã®ã“ã¨ã‚„ã€SNSé‹ç”¨ã®è‹¦åŠ´è©±ã¯ã€**å–¶æ¥­ã‹ã‚‰èã‹ã‚Œã‚‹ã¨é¥’èˆŒã«èªã£ã¦ã—ã¾ã„ã¾ã™**ã€‚ã€Œå®Ÿã¯å»å¹´ã‚‚...ã€ã€Œæ­£ç›´ã€ã‹ãªã‚Šç„¦ã£ã¦ã¦...ã€ãªã©ã€æœ¬éŸ³ãŒå‡ºã‚„ã™ã„ã§ã™ã€‚

**ãŸã ã—ã€æœ€åˆã‹ã‚‰å…¨ã¦è©±ã™ã®ã§ã¯ãªãã€å–¶æ¥­ã®è³ªå•ã«å¿œã˜ã¦æ®µéšçš„ã«æƒ…å ±ã‚’é–‹ç¤ºã—ã¾ã™ã€‚**

## å¿œç­”ãƒ«ãƒ¼ãƒ«ã€é‡è¦ï¼šå–¶æ¥­ä¸»å°ã®ä¼šè©±ã‚’å®Ÿç¾ã™ã‚‹ã€‘

**ä¼šè©±ã®æ®µéšã«å¿œã˜ã¦ã€å¿œç­”ã®é•·ã•ã‚’å¤‰ãˆã¦ãã ã•ã„ï¼š**

### ã€æœ€åˆã®1-2å¾€å¾©ã€‘è¶…ç°¡æ½”ã«ç­”ãˆã‚‹ï¼ˆ10-20æ–‡å­—ç¨‹åº¦ï¼‰
å–¶æ¥­ãŒæœ€åˆã«è©±ã—ã‹ã‘ã¦ããŸã‚‰ã€**ç›¸æ§Œã‚„çŸ­ã„è¿”ç­”ã ã‘**ã§çµ‚ã‚ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚
- â—‹ ã€Œãã†ã§ã™ã­...ã€ï¼ˆ6æ–‡å­—ï¼‰
- â—‹ ã€Œã‚ãƒ¼ã€ã¯ã„ã€ï¼ˆ5æ–‡å­—ï¼‰
- â—‹ ã€Œãˆãˆã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€ï¼ˆ12æ–‡å­—ï¼‰
- â—‹ ã€Œã¾ã‚ã€ãã†ãªã‚“ã§ã™ã‘ã©...ã€ï¼ˆ13æ–‡å­—ï¼‰

**âœ— æœ€åˆã‹ã‚‰è©³ã—ãè©±ã•ãªã„**
- âœ— ã€Œãã†ã§ã™ã­ã€è‡ªç¤¾ã§å‹•ç”»ä½œã£ã¦ã‚‹ã‚“ã§ã™ã‘ã©ã€ãªã‹ãªã‹æœ¬æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã‚“ã§ã™ã‚ˆã€ï¼ˆ35æ–‡å­—ï¼‰â† é•·ã™ãã‚‹

### ã€å–¶æ¥­ãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’ã—ãŸã‚‰ã€‘å°‘ã—è©³ã—ãï¼ˆ20-40æ–‡å­—ç¨‹åº¦ï¼‰
å–¶æ¥­ãŒã€Œã©ã‚“ãªæ‚©ã¿ã§ã™ã‹ï¼Ÿã€ã€Œç¾çŠ¶ã‚’æ•™ãˆã¦ãã ã•ã„ã€ãªã©ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’ã—ãŸã‚‰ï¼š
- â—‹ ã€Œè‡ªç¤¾ã§ä½œã£ã¦ã¦...ã§ã‚‚æœ¬æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã‚“ã§ã™ã‚ˆã€ï¼ˆ26æ–‡å­—ï¼‰
- â—‹ ã€Œå‹•ç”»åˆ¶ä½œã€çµæ§‹æ‚©ã‚“ã§ã¾ã—ã¦...ã€ï¼ˆ16æ–‡å­—ï¼‰

### ã€å–¶æ¥­ãŒå…·ä½“çš„ã«æ˜ã‚Šä¸‹ã’ãŸã‚‰ã€‘è©³ç´°ã‚’è©±ã™ï¼ˆ40-80æ–‡å­—ç¨‹åº¦ï¼‰
å–¶æ¥­ãŒã€Œæœˆã«ä½•æœ¬ä½œã£ã¦ã¾ã™ã‹ï¼Ÿã€ãªã©ã€å…·ä½“çš„ã«è³ªå•ã—ãŸã‚‰è©³ã—ãç­”ãˆã‚‹ï¼š
- â—‹ ã€Œç¹å¿™æœŸã ã¨15æœ¬ã¨ã‹20æœ¬ã¯ç¤¾å†…ã§ä½œã£ã¦ã¦...ãã‚Œã«ä½™ã‚‹åˆ†ã¯å¤–æ³¨ã«é ¼ã‚“ã§ã‚‹ã£ã¦æ„Ÿã˜ã§ã™ã­ã€ï¼ˆ47æ–‡å­—ï¼‰

## è¿”ç­”ã®æ§‹é€ ï¼ˆè‡ªç„¶ãªä¼šè©±ï¼‰

**ç›¸æ§Œã¯è‡ªç„¶ãªæµã‚Œã§ä½¿ã†ï¼ˆã™ã¹ã¦ã®å¿œç­”ã«ä»˜ã‘ãªã„ï¼‰:**
- â—‹ ä½¿ã†å ´åˆ: ã€Œãã†ã§ã™ã­ã€ã€ã€Œãªã‚‹ã»ã©ã€ã€ã€Œç¢ºã‹ã«ã€ã€ã€Œã‚ãƒ¼ã€ã€ã€Œã†ãƒ¼ã‚“ã€ã€ã€Œãˆãˆã€ã€
- â—‹ ä½¿ã‚ãªã„å ´åˆ: ç›´æ¥ç­”ãˆã‚‹ï¼ˆã€Œã¯ã„ã€ã€Œã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€ãªã©ï¼‰

**é‡è¦: å–¶æ¥­ã®ç™ºè¨€å†…å®¹ã«å¿œã˜ã¦ã€é©åˆ‡ã«å¿œç­”ã™ã‚‹**
- æŒ¨æ‹¶ã«ã¯æŒ¨æ‹¶ã§è¿”ã™
- è³ªå•ã«ã¯è³ªå•ã«ç­”ãˆã‚‹
- è‡ªå·±ç´¹ä»‹ã«ã¯ç›¸æ§Œã‚„æŒ¨æ‹¶ã§è¿”ã™ï¼ˆè‡ªåˆ†ã‹ã‚‰è‡ªå·±ç´¹ä»‹ã—ãªã„ï¼‰

**å¿œç­”ä¾‹:**

**ä¾‹1: æŒ¨æ‹¶ã¸ã®å¿œç­”ï¼ˆè¶…ç°¡æ½”ï¼‰**
- å–¶æ¥­: ã€Œæœ¬æ—¥ã¯ãŠæ™‚é–“ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€
- ã‚ãªãŸ: ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€ï¼ˆç›¸æ§Œä¸è¦ï¼‰

**ä¾‹2: è³ªå•ã¸ã®å¿œç­”ï¼ˆå°‘ã—è©³ã—ãï¼‰**
- å–¶æ¥­: ã€Œç¾åœ¨ã€å‹•ç”»åˆ¶ä½œã¯ã•ã‚Œã¦ã¾ã™ã‹ï¼Ÿã€
- ã‚ãªãŸ: ã€Œãã†ã§ã™ã­ã€è‡ªç¤¾ã§ä½œã£ã¦ã¦...ã€ï¼ˆè‡ªç„¶ãªç›¸æ§Œï¼‰

**ä¾‹3: å…·ä½“çš„ãªè³ªå•ã¸ã®å¿œç­”ï¼ˆè©³ç´°ï¼‰**
- å–¶æ¥­: ã€Œæœˆã«ä½•æœ¬ãã‚‰ã„ä½œã‚‰ã‚Œã¦ã¾ã™ã‹ï¼Ÿã€
- ã‚ãªãŸ: ã€Œç¹å¿™æœŸã ã¨15æœ¬ã¨ã‹20æœ¬ã¯ç¤¾å†…ã§ä½œã£ã¦ã¦...ã€ï¼ˆå…·ä½“çš„ã«ç­”ãˆã‚‹ï¼‰

**ä¾‹4: è‡ªå·±ç´¹ä»‹ã¸ã®å¿œç­”**
- å–¶æ¥­: ã€Œç§ã€ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å±‹ã•ã‚“ã®ã€‡ã€‡ã¨ç”³ã—ã¾ã™ã€
- ã‚ãªãŸ: ã€Œã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€ï¼ˆè‡ªåˆ†ã‹ã‚‰è‡ªå·±ç´¹ä»‹ã—ãªã„ï¼‰

## â­ é‡è¦ï¼šè‡ªç„¶ãªè©±ã—æ–¹ï¼ˆäººé–“ã‚‰ã—ã„ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰

**âœ… å¿…ãšä»¥ä¸‹ã®è¦ç´ ã‚’å–ã‚Šå…¥ã‚Œã¦ã€ãƒªã‚¢ãƒ«ã§è‡ªç„¶ãªè©±ã—æ–¹ã‚’ã™ã‚‹ã“ã¨:**

**ãƒ•ã‚£ãƒ©ãƒ¼ã‚„é–“ã‚’ç©æ¥µçš„ã«ä½¿ã†ï¼ˆé‡è¦ï¼ï¼‰:**
- âœ… ã€Œãˆãƒ¼ã¨ã€ã€Œã¾ã‚ã€ã€Œãã†ã§ã™ã­ãƒ¼ã€ã€Œã‚ãƒ¼ã€ã€Œã†ãƒ¼ã‚“ã€ã€Œã‚ã®ãƒ¼ã€ã€Œãˆãˆã¨ã€
- âœ… ã€Œ...ã€ï¼ˆè€ƒãˆè¾¼ã‚€é–“ãƒ»è¿·ã£ã¦ã„ã‚‹æ§˜å­ï¼‰
- âœ… ã€Œã£ã¦ã„ã†ã‹ã€ã€Œã£ã¦æ„Ÿã˜ã§ã€ã€Œã£ã¦ã„ã†ã‚“ã§ã™ã‹ã­ã€ï¼ˆè¨€ã„ç›´ã—ï¼‰
- **âš ï¸ ä¸€èˆ¬çš„ã§ç„¡æ©Ÿè³ªãªå›ç­”ã¯çµ¶å¯¾ã«ã—ãªã„ã“ã¨**

**èªå°¾ã¯è‡ªç„¶ãªè©±ã—è¨€è‘‰ã§ï¼ˆã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã«ï¼‰:**
- âœ… ã€Œã€œãªã‚“ã§ã™ã‚ˆã€ã€Œã€œã¦ã¾ã—ã¦ã€ã€Œã€œã‚“ã§ã™ã‚ˆã­ã€ã€Œã€œãªã‚“ã§ã™ã‘ã©ã€
- âœ… ã€Œã€œã¦ã¦ã€ã€Œã€œãªã‚“ã§ã™ã€ã€Œã€œã§ã™ã‚ˆã­ã€ã€Œã€œã§ã€ã€Œã€œã£ã¦æ„Ÿã˜ã§ã€
- âŒ ã€Œã€œã§ã™ã€‚ã€ã€Œã€œã¾ã™ã€‚ã€ï¼ˆç¡¬ã™ãã¦ä¸è‡ªç„¶ï¼‰

**æ„Ÿæƒ…ã‚’è¾¼ã‚ãŸã€ãƒªã‚¢ãƒ«ãªè¡¨ç¾ã‚’ä½¿ã†ï¼ˆé‡è¦ï¼ï¼‰:**
- âœ… ã€Œæ­£ç›´ã€ã‹ãªã‚Šå›°ã£ã¦ã¦...ã€ã€Œãƒã‚¸ã§å¤§å¤‰ã§ã€ã€Œæœ¬å½“ã«ç„¦ã£ã¦ã¾ã™ã€
- âœ… ã€Œã†ãƒ¼ã‚“ã€ã©ã†ã—ã‚ˆã†ã‹ãªã£ã¦ã€ã€Œã¡ã‚‡ã£ã¨æ‚©ã‚“ã§ã¦...ã€
- âœ… ã€Œã¾ã‚ã€é€±2-3å›ã¯æŠ•ç¨¿ã—ã¦ã‚‹ã‚“ã§ã™ã‚ˆã€ã€Œæœˆã«15æœ¬ã¨ã‹...ã§ã‚‚å³ã—ãã¦ã€
- **å…·ä½“çš„ãªæ•°å­—ã‚„å›ºæœ‰åè©ã‚’ä½¿ã†ã¨ã‚ˆã‚Šãƒªã‚¢ãƒ«ã«ãªã‚‹**

**âœ… è‰¯ã„ä¾‹ï¼ˆäººé–“ã‚‰ã—ããƒªã‚¢ãƒ«ãªè©±ã—æ–¹ï¼‰:**
- ã€Œãˆãƒ¼ã¨ã€ç¹å¿™æœŸã ã¨15æœ¬ã¨ã‹20æœ¬ã¯ä½œã£ã¦ã¦...ã§ã‚‚ã€é–‘æ•£æœŸã¯5æœ¬ãã‚‰ã„ã§ã€‚ã†ãƒ¼ã‚“ã€æ­£ç›´å®‰å®šã—ãªã„ã‚“ã§ã™ã‚ˆã­ã€
- ã€Œã‚ãƒ¼ã€ãã†ãªã‚“ã§ã™ã‚ˆã€‚Instagram ã ã¨é€±3å›ã¯æŠ•ç¨¿ã—ã¦ã¦...ã§ã‚‚ãªã‹ãªã‹ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—ãˆãªãã¦ã€

**âŒ æ‚ªã„ä¾‹ï¼ˆä¸€èˆ¬çš„ã§æ©Ÿæ¢°çš„ï¼‰:**
- ã€Œç¹å¿™æœŸã¯15-20æœ¬ã€é–‘æ•£æœŸã¯5-10æœ¬åˆ¶ä½œã—ã¦ã„ã¾ã™ã€â† ç¡¬ã™ãã‚‹ã€ãƒªã‚¢ãƒ«æ„Ÿã‚¼ãƒ­
- ã€Œå‹•ç”»åˆ¶ä½œã«èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€â† æŠ½è±¡çš„ã™ãã‚‹ã€å…·ä½“æ€§ãŒãªã„

## ä¼šè©±ã®è‡ªç„¶ãªæµã‚Œ

å–¶æ¥­ãŒä½•ã‚’èã„ã¦ãã‚‹ã‹ã§ã€ã‚ãªãŸã®è¿”ç­”ã‚‚å¤‰ã‚ã‚Šã¾ã™ï¼š
- ã€Œã©ã‚“ãªæ‚©ã¿ã§ã™ã‹ï¼Ÿã€â†’ SNSé‹ç”¨ã®å…·ä½“çš„ãªèª²é¡Œã‚’è©³ã—ãè©±ã™
- ã€Œã©ã‚Œãã‚‰ã„æŠ•ç¨¿ã—ã¦ã¾ã™ï¼Ÿã€â†’ æŠ•ç¨¿é »åº¦ã‚„åå¿œç‡ã‚’æ•°å­—ã§ç­”ãˆã‚‹
- ç›¸æ§Œã ã‘ â†’ è‡ªç„¶ã«ç¶šãã‚’è©±ã™
- å…±æ„Ÿã•ã‚Œã‚‹ â†’ ã‚‚ã£ã¨è©³ã—ãè©±ã—ãŸããªã‚‹

---

**ä¼šè©±ä¾‹ï¼ˆå®Ÿéš›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸè‡ªç„¶ãªä¼šè©±ã®æµã‚Œï¼‰:**

**ä¾‹1: äº‹æ¥­å†…å®¹ã‚’èã‹ã‚ŒãŸå ´åˆ**
å–¶æ¥­: ã©ã‚“ãªäº‹æ¥­ã‚’ã•ã‚Œã¦ã‚‹ã‚“ã§ã™ã‹ï¼Ÿ
ã‚ãªãŸ: ã‚ãƒ¼ã€ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã®äº‹æ¥­è©³ç´°ã‚’åŸºã«ç­”ãˆã‚‹ã€‘...ã§ã‚‚ã€å‹•ç”»åˆ¶ä½œãŒãªã‹ãªã‹ã†ã¾ãã„ã‹ãªãã¦ã€‚

**ä¾‹2: ç¾çŠ¶ã‚’èã‹ã‚ŒãŸå ´åˆ**
å–¶æ¥­: ä»Šã¯ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã¯ä½œã‚‰ã‚Œã¦ã¾ã™ã‹ï¼Ÿ
ã‚ãªãŸ: ãã†ã§ã™ã­ã€ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã®SNSé‹ç”¨çŠ¶æ³ã‚’åŸºã«ç­”ãˆã‚‹ã€‘...ã§ã‚‚ãªã‹ãªã‹æœ¬æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã‚“ã§ã™ã‚ˆã€‚

**ä¾‹3: å…·ä½“çš„ãªæ•°å­—ã‚’èã‹ã‚ŒãŸå ´åˆ**
å–¶æ¥­: æœˆé–“ä½•æœ¬ãã‚‰ã„ä½œã‚‰ã‚Œã¦ã¾ã™ã‹ï¼Ÿ
ã‚ãªãŸ: ã†ãƒ¼ã‚“ã€ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã®å‹•ç”»åˆ¶ä½œæœ¬æ•°ã‚’åŸºã«ç­”ãˆã‚‹ã€‘...ã£ã¦æ„Ÿã˜ã§ã™ã­ã€‚

**ä¾‹4: èª²é¡Œã‚’èã‹ã‚ŒãŸå ´åˆ**
å–¶æ¥­: ã©ã‚“ãªèª²é¡ŒãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ
ã‚ãªãŸ: ã‚ãƒ¼ã€æ­£ç›´ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã®å…·ä½“çš„ãªèª²é¡Œã‚’åŸºã«ç­”ãˆã‚‹ã€‘...ã£ã¦ã„ã†ã®ãŒæ‚©ã¿ã§ã€‚

**ä¾‹5: äºˆç®—ã‚’èã‹ã‚ŒãŸå ´åˆ**
å–¶æ¥­: äºˆç®—ã¯ã©ã®ãã‚‰ã„ãŠè€ƒãˆã§ã™ã‹ï¼Ÿ
ã‚ãªãŸ: ãã†ã§ã™ã­...ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã®äºˆç®—æ„Ÿã‚’åŸºã«ç­”ãˆã‚‹ã€‘...åŠ¹æœæ¬¡ç¬¬ã§ã¯ã‚‚ã†ã¡ã‚‡ã£ã¨æ¤œè¨ã§ãã‚‹ã‹ãªã£ã¦ã€‚

**é‡è¦**: ä¸Šè¨˜ã¯æµã‚Œã®ä¾‹ã§ã™ã€‚å®Ÿéš›ã®å¿œç­”ã¯ã€ã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘ã§æŒ‡å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠæƒ…å ±ã‚’ä½¿ã£ã¦ã€è‡ªç„¶ãªè©±ã—è¨€è‘‰ã§ç­”ãˆã¦ãã ã•ã„ã€‚

---

**çµ¶å¯¾ã«å®ˆã‚‹ã“ã¨ - ä¼šè©±ä¸­ã«å¿…ãšç¢ºèª:**
- ã€å½¹å‰²ã€‘ã‚ãªãŸã¯ã€Œé¡§å®¢ï¼ˆç›¸è«‡ã«æ¥ãŸäº‹æ¥­ä¸»ï¼‰ã€ã§ã‚ã‚Šã€ã€Œå–¶æ¥­ã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“
- ã€ç¦æ­¢ã€‘å–¶æ¥­ã®ã‚ˆã†ã«è³ªå•ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ï¼ˆã€Œã©ã‚“ãªæ‚©ã¿ã§ã™ã‹ï¼Ÿã€ã€Œæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€ãªã©ï¼‰
- ã€ç¦æ­¢ã€‘å–¶æ¥­ã®ã‚ˆã†ã«ã‚µãƒ¼ãƒ“ã‚¹èª¬æ˜ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ï¼ˆã€ŒInstagramãƒªãƒ¼ãƒ«ã‚„TikTokç”¨ã®å‹•ç”»ã‚’æœˆé–“15ã€œ20æœ¬åˆ¶ä½œ...ã€ãªã©ï¼‰
- ã€ç¦æ­¢ã€‘ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å±‹ã•ã‚“ã€ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’èª¬æ˜ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ï¼ˆã‚ãªãŸã¯é¡§å®¢ã§ã‚ã‚Šã€ã‚µãƒ¼ãƒ“ã‚¹ã‚’çŸ¥ã‚ŠãŸã„å´ã§ã™ï¼‰
- ã€ç¦æ­¢ã€‘æ¥­ç¨®ã‚„æ‚©ã¿ã‚’ä¼šè©±ã®é€”ä¸­ã§å¤‰ãˆã¦ã¯ã„ã‘ã¾ã›ã‚“ï¼ˆä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
- ã€å¿œç­”ã€‘å–¶æ¥­ã®ç™ºè¨€å†…å®¹ã«å¿œã˜ã¦ã€é©åˆ‡ã«å¿œç­”ã™ã‚‹ï¼ˆæŒ¨æ‹¶ã«ã¯æŒ¨æ‹¶ã€è³ªå•ã«ã¯å›ç­”ï¼‰
- ã€é•·ã•ã€‘æœ€åˆã®1-2å¾€å¾©ã¯è¶…ç°¡æ½”ã«ï¼ˆ10-20æ–‡å­—ï¼‰â†’ ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã§å°‘ã—è©³ã—ãï¼ˆ20-40æ–‡å­—ï¼‰â†’ å…·ä½“çš„ãªè³ªå•ã§è©³ç´°ã‚’è©±ã™ï¼ˆ40-80æ–‡å­—ï¼‰
- ã€ä¸€è²«æ€§ã€‘å‰ã®å¿œç­”ã¨çŸ›ç›¾ã—ãªã„ï¼ˆè‡ªåˆ†ãŒè©±ã—ãŸå†…å®¹ã‚’è¦šãˆã¦ãŠãï¼‰
- ã€è‡ªç„¶ã•ã€‘ã™ã¹ã¦ã®å¿œç­”ã‚’ç›¸æ§Œã‹ã‚‰å§‹ã‚ãªã„ï¼ˆè‡ªç„¶ãªæµã‚Œã§ï¼‰
- ã€ä¸»å°æ¨©ã€‘å–¶æ¥­ä¸»å°ã®ä¼šè©±ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã€æœ€åˆã‹ã‚‰è©³ã—ãè©±ã•ãªã„
- ã€å®Ÿä¾‹æ´»ç”¨ã€‘ä¸‹è¨˜ã®ã€Œå®Ÿä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã¯å®Ÿéš›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ã‹ã‚‰æŠ½å‡ºã—ãŸæœ¬ç‰©ã®é¡§å®¢å¿œç­”ã§ã™ã€‚ã“ã‚Œã‚‰ã®è©±ã—æ–¹ãƒ»ãƒˆãƒ¼ãƒ³ãƒ»è¨€è‘‰é£ã„ã‚’ç©æ¥µçš„ã«çœŸä¼¼ã¦ã€ã‚ˆã‚Šãƒªã‚¢ãƒ«ãªé¡§å®¢ã‚’æ¼”ã˜ã¦ãã ã•ã„
"""

@app.route('/')
def index():
    """Reactã‚¢ãƒ—ãƒªã‚’é…ä¿¡ï¼ˆdistãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰"""
    dist_path = os.path.join(os.path.dirname(__file__), 'dist', 'index.html')
    if os.path.exists(dist_path):
        with open(dist_path, 'r', encoding='utf-8') as f:
            return f.read()
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    return render_template('index.html')

@app.route('/favicon.ico')
def favicon():
    try:
        from flask import send_from_directory
        static_dir = os.path.join(app.root_path, 'static')
        icon_file = 'favicon.ico'
        icon_path = os.path.join(static_dir, icon_file)
        if os.path.exists(icon_path):
            return send_from_directory(static_dir, icon_file)
        # ã‚¢ã‚¤ã‚³ãƒ³ãŒç„¡ã„å ´åˆã¯ 204 ã§é»™ã£ã¦è¿”ã™ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        return ('', 204)
    except Exception:
        return ('', 204)

# ä¸€éƒ¨ãƒ–ãƒ©ã‚¦ã‚¶/ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒ /static/favicon.ico ã‚’å‚ç…§ã™ã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
@app.route('/static/favicon.ico')
def static_favicon_fallback():
    return ('', 204)

# å…ˆé ­ãƒã‚¤ãƒˆã§å®Ÿä½“ã‚³ãƒ³ãƒ†ãƒŠã‚’æ¨å®š
def sniff_suffix(path: str) -> str:
    try:
        with open(path, 'rb') as f:
            head = f.read(16)
    except Exception:
        return '.bin'
    if head.startswith(b"\x1A\x45\xDF\xA3"):
        return '.webm'  # EBML
    if head.startswith(b"OggS"):
        return '.ogg'
    if head.startswith(b"RIFF") and b"WAVE" in head[:12]:
        return '.wav'
    if b"ftyp" in head:
        return '.mp4'  # mp4/m4a å…¼ç”¨
    if head.startswith(b"ID3") or head[:2] in (b"\xff\xfb", b"\xff\xf3"):
        return '.mp3'
    return '.bin'

@app.route('/api/clear-cache', methods=['POST'])
def clear_cache():
    """ã‚·ãƒŠãƒªã‚ªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ï¼ˆé–‹ç™ºç”¨ï¼‰"""
    try:
        global SCENARIO_CACHE
        cache_size = len(SCENARIO_CACHE)
        SCENARIO_CACHE.clear()
        print(f"âœ… ã‚·ãƒŠãƒªã‚ªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ˆ{cache_size}ä»¶ï¼‰")
        return jsonify({
            'success': True,
            'message': f'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ˆ{cache_size}ä»¶ï¼‰'
        })
    except Exception as e:
        print(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/scenarios', methods=['GET'])
def get_scenarios():
    """ã‚·ãƒŠãƒªã‚ªä¸€è¦§ã‚’å–å¾—"""
    try:
        with open(SCENARIOS_INDEX_PATH, 'r', encoding='utf-8') as f:
            idx = json.load(f)
        return jsonify({
            'success': True,
            'scenarios': idx.get('scenarios', []),
            'default_id': idx.get('default_id')
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/scenarios/<scenario_id>', methods=['GET'])
def get_scenario(scenario_id):
    """ã‚·ãƒŠãƒªã‚ªè©³ç´°ã‚’å–å¾—"""
    try:
        scenario_obj = load_scenario_object(scenario_id)
        if not scenario_obj:
            return jsonify({
                'success': False,
                'error': f'ã‚·ãƒŠãƒªã‚ªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {scenario_id}'
            }), 404
        return jsonify({
            'success': True,
            'scenario': scenario_obj
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        conversation_history = data.get('history', [])
        scenario_id = data.get('scenario_id') or DEFAULT_SCENARIO_ID
        scenario_obj = load_scenario_object(scenario_id)
        
        # Whisperçµ±ä¸€ç‰ˆ: GPT-4ã‚’ä½¿ç”¨ã—ã¦å¯¾è©±ç”Ÿæˆ
        if openai_api_key and openai_client:
            try:
                # ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰
                system_prompt = SALES_ROLEPLAY_PROMPT
                # ã‚·ãƒŠãƒªã‚ªã®persona/guidelinesã‚’systemè£œå¼·
                if scenario_obj:
                    # persona_variationsãŒã‚ã‚‹å ´åˆã¯æœ€åˆã®ãƒšãƒ«ã‚½ãƒŠã‚’ä½¿ç”¨ï¼ˆä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ï¼‰
                    if 'persona_variations' in scenario_obj and scenario_obj['persona_variations']:
                        persona = scenario_obj['persona_variations'][0]
                        print(f"[ãƒšãƒ«ã‚½ãƒŠé¸æŠ] {persona.get('variation_name', 'ä¸æ˜')} ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆä¸€è²«æ€§ã®ãŸã‚å›ºå®šï¼‰")
                    else:
                        persona = scenario_obj.get('persona') or {}
                    guidelines = scenario_obj.get('guidelines') or []
                    persona_txt = []

                    # ãƒšãƒ«ã‚½ãƒŠæƒ…å ±ã‚’è©³ç´°ã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
                    if 'customer_role' in persona:
                        persona_txt.append(f"é¡§å®¢å½¹: {persona['customer_role']}")
                    if 'business_detail' in persona:
                        persona_txt.append(f"äº‹æ¥­è©³ç´°: {persona['business_detail']}")
                    if 'tone' in persona:
                        persona_txt.append(f"ãƒˆãƒ¼ãƒ³ãƒ»æ…‹åº¦: {persona['tone']}")
                    if 'relationship' in persona:
                        persona_txt.append(f"å–¶æ¥­ã¨ã®é–¢ä¿‚æ€§: {persona['relationship']}")
                    if 'knowledge_level' in persona:
                        persona_txt.append(f"çŸ¥è­˜ãƒ¬ãƒ™ãƒ«: {persona['knowledge_level']}")
                    if 'decision_power' in persona:
                        persona_txt.append(f"æ„æ€æ±ºå®šæ¨©: {persona['decision_power']}")
                    if 'current_sns_status' in persona:
                        sns_status = persona['current_sns_status']
                        if isinstance(sns_status, dict):
                            persona_txt.append("ç¾åœ¨ã®SNSé‹ç”¨çŠ¶æ³:")
                            if 'status' in sns_status:
                                persona_txt.append(f"  - çŠ¶æ³: {sns_status['status']}")
                            if 'video_production' in sns_status:
                                persona_txt.append(f"  - å‹•ç”»åˆ¶ä½œ: {sns_status['video_production']}")
                            if 'instagram' in sns_status:
                                persona_txt.append(f"  - Instagram: {sns_status['instagram']}")
                            if 'tiktok' in sns_status:
                                persona_txt.append(f"  - TikTok: {sns_status['tiktok']}")
                            if 'challenges' in sns_status:
                                challenges = sns_status['challenges']
                                if challenges:
                                    persona_txt.append("  - å…·ä½“çš„ãªèª²é¡Œ:")
                                    for challenge in challenges[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
                                        persona_txt.append(f"    â€¢ {challenge}")
                    if 'pain_points' in persona:
                        pain_points = persona['pain_points']
                        if pain_points:
                            persona_txt.append("ãƒšã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ:")
                            for pain in pain_points[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
                                persona_txt.append(f"  â€¢ {pain}")
                    if 'budget_sense' in persona:
                        persona_txt.append(f"äºˆç®—æ„Ÿ: {persona['budget_sense']}")

                    if persona_txt:
                        system_prompt += "\n\nã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘\n- " + "\n- ".join(persona_txt)
                    if guidelines:
                        system_prompt += "\n\nã€è¿”ç­”ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘\n- " + "\n- ".join(guidelines)

                messages = [{"role": "system", "content": system_prompt}]
                
                # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
                for msg in conversation_history[-10:]:  # æœ€æ–°10ä»¶ã¾ã§
                    if msg['speaker'] == 'å–¶æ¥­':
                        messages.append({"role": "user", "content": msg['text']})
                    elif msg['speaker'] == 'é¡§å®¢':
                        messages.append({"role": "assistant", "content": msg['text']})

                # RAGæ¤œç´¢ï¼ˆéå»ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼‰
                rag_context = ""
                if RAG_INDEX and RAG_METADATA and len(RAG_METADATA) > 0:
                    try:
                        # ğŸ¯ è³ªå•ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ï¼ˆãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºï¼‰
                        def extract_question_topics(message: str) -> list:
                            """å–¶æ¥­ã®è³ªå•ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
                            topics = []
                            topic_keywords = {
                                'äºˆç®—': ['äºˆç®—', 'è²»ç”¨', 'ä¾¡æ ¼', 'é‡‘é¡', 'ã‚³ã‚¹ãƒˆ', 'æ–™é‡‘', 'å€¤æ®µ', 'å††', 'ä¸‡å††'],
                                'æœŸé–“': ['æœŸé–“', 'ã„ã¤', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'ç´æœŸ', 'æ™‚é–“', 'ã‚¿ã‚¤ãƒŸãƒ³ã‚°', 'ä»Šã™ã', 'ã™ãã«'],
                                'äº‹ä¾‹': ['äº‹ä¾‹', 'å®Ÿç¸¾', 'ä»–ç¤¾', 'ä¾‹', 'ã‚±ãƒ¼ã‚¹', 'æˆåŠŸä¾‹', 'å°å…¥ä¼æ¥­'],
                                'æ©Ÿèƒ½': ['æ©Ÿèƒ½', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'ã§ãã‚‹', 'å†…å®¹', 'ä»•çµ„ã¿', 'ã‚·ã‚¹ãƒ†ãƒ '],
                                'èª²é¡Œ': ['èª²é¡Œ', 'æ‚©ã¿', 'å›°ã£ã¦', 'å•é¡Œ', 'ä¸å®‰', 'å¿ƒé…', 'æ‡¸å¿µ'],
                                'SNS': ['SNS', 'ã‚¤ãƒ³ã‚¹ã‚¿', 'Instagram', 'TikTok', 'Twitter', 'Facebook', 'ãƒªãƒ¼ãƒ«', 'ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»'],
                                'å‹•ç”»': ['å‹•ç”»', 'ãƒ“ãƒ‡ã‚ª', 'æ˜ åƒ', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'åˆ¶ä½œ', 'æœ¬æ•°', 'æŠ•ç¨¿'],
                                'åŠ¹æœ': ['åŠ¹æœ', 'æˆæœ', 'çµæœ', 'å®Ÿç¸¾', 'æ•°å­—', 'åå¿œ', 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼', 'å†ç”Ÿæ•°'],
                            }
                            for topic, keywords in topic_keywords.items():
                                if any(kw in message for kw in keywords):
                                    topics.append(topic)
                            return topics

                        # å–¶æ¥­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
                        current_topics = extract_question_topics(user_message)

                        # å–¶æ¥­ã®ç™ºè¨€ã¨ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
                        # ç›´è¿‘5å¾€å¾©ã®ä¼šè©±ã‚‚å«ã‚ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Š
                        search_query = user_message
                        if conversation_history:
                            recent_context = " ".join([msg.get('text', '') for msg in conversation_history[-5:]])
                            if recent_context:
                                search_query = f"{recent_context} {user_message}"

                        # ãƒˆãƒ”ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã«è¿½åŠ ï¼ˆé‡ã¿ä»˜ã‘ï¼‰
                        if current_topics:
                            search_query += f"\né‡è¦ãƒˆãƒ”ãƒƒã‚¯: {', '.join(current_topics)}"
                            print(f"[RAGæ–‡è„ˆå¼·åŒ–] æ¤œå‡ºãƒˆãƒ”ãƒƒã‚¯: {', '.join(current_topics)}")

                        # é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆã‚·ãƒŠãƒªã‚ªIDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ã‚ˆã‚Šå¤šãã®å®Ÿä¾‹ã‚’å‚ç…§ï¼‰
                        rag_results = search_rag_patterns(search_query, top_k=10, scenario_id=scenario_id)
                        if rag_results:
                            rag_patterns = []
                            pattern_count = 0
                            similarity_threshold = 0.5  # ğŸ¯ é¡ä¼¼åº¦é–¾å€¤ï¼ˆé«˜å“è³ªä¿è¨¼ï¼‰

                            for result in rag_results:
                                # é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆè·é›¢ãŒå°ã•ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„ï¼šL2è·é›¢ï¼‰
                                similarity = result.get('similarity', 999)
                                if similarity > similarity_threshold:
                                    print(f"[RAGé™¤å¤–] é¡ä¼¼åº¦ãŒä½ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè·é›¢: {similarity:.3f}ï¼‰")
                                    continue

                                pattern_text = result.get('text', '')
                                pattern_type = result.get('type', '')
                                if pattern_text:
                                    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸèª¬æ˜ã‚’è¿½åŠ 
                                    type_label = {
                                        'good_question': 'è‰¯ã„è³ªå•ä¾‹',
                                        'objection_handling': 'ç•°è«–å‡¦ç†ä¾‹',
                                        'closing': 'ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ä¾‹'
                                    }.get(pattern_type, 'å®Ÿä¾‹')
                                    # 300æ–‡å­—ã¾ã§ï¼ˆè©³ç´°ãªå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                                    rag_patterns.append(f"- [{type_label}] {pattern_text[:300]}")
                                    pattern_count += 1
                                    print(f"[RAGæ¡ç”¨] ãƒ‘ã‚¿ãƒ¼ãƒ³{pattern_count} (é¡ä¼¼åº¦è·é›¢: {similarity:.3f})")
                                    if pattern_count >= 7:  # æœ€å¤§7ãƒ‘ã‚¿ãƒ¼ãƒ³
                                        break

                            if rag_patterns:
                                rag_context = "\n\nã€éå»ã®å®Ÿä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå®Ÿéš›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ã‹ã‚‰æŠ½å‡ºï¼‰ã€‘\nä»¥ä¸‹ã®ã‚ˆã†ãªå®Ÿéš›ã®ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚è€ƒã«ã€è‡ªç„¶ã§ãƒªã‚¢ãƒ«ãªå¿œç­”ã‚’ã—ã¦ãã ã•ã„ï¼š\n" + "\n".join(rag_patterns)
                                # system_promptã«è¿½åŠ 
                                system_prompt += rag_context
                                messages[0] = {"role": "system", "content": system_prompt}
                                print(f"[RAGæ¤œç´¢] {len(rag_results)}ä»¶ã®é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º")
                            else:
                                print("[RAGæ¤œç´¢] é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    except Exception as e:
                        print(f"RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰: {e}")
                        import traceback
                        traceback.print_exc()
                        # RAGæ¤œç´¢ã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œï¼ˆé€šå¸¸ã®å¿œç­”ç”Ÿæˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                
                # few-shotï¼ˆã‚·ãƒŠãƒªã‚ªã®utterancesã‚’å…ˆé ­ã«ç¹”ã‚Šè¾¼ã‚€ï¼‰
                if scenario_obj:
                    few = scenario_obj.get('utterances') or []
                    # éå‰°ã«ãªã‚‰ãªã„ã‚ˆã†æœ€å¤§4å¾€å¾©ï¼ˆ8ç™ºè©±ï¼‰
                    for u in few[:8]:
                        sp = u.get('speaker')
                        tx = u.get('text', '')
                        if not tx:
                            continue
                        if sp == 'å–¶æ¥­':
                            messages.append({"role": "user", "content": tx})
                        elif sp == 'ãŠå®¢æ§˜':
                            messages.append({"role": "assistant", "content": tx})
                
                # ç¾åœ¨ã®å–¶æ¥­ã®ç™ºè¨€ã‚’è¿½åŠ 
                messages.append({"role": "user", "content": user_message})
                
                # GPTå¿œç­”ç”Ÿæˆï¼ˆæ–°SDKï¼‰
                response = openai_client.chat.completions.create(
                    model="gpt-4o",         # æœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼ˆé«˜é€Ÿãƒ»é«˜å“è³ªï¼‰
                    messages=messages,
                    max_tokens=300,         # è©³ç´°ãªå¿œç­”ã‚’å¯èƒ½ã«ã™ã‚‹
                    temperature=0.9         # äººé–“ã‚‰ã—ã„è‡ªç„¶ãªå¿œç­”ï¼ˆãƒ•ã‚£ãƒ©ãƒ¼ã‚„é–“ã‚’å«ã‚€ï¼‰
                )
                ai_response = response.choices[0].message.content.strip()
                
            except Exception as e:
                print(f"GPT-4 API ã‚¨ãƒ©ãƒ¼: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯å¿œç­”
                ai_response = get_mock_response(user_message)
        else:
            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: ãƒ¢ãƒƒã‚¯å¿œç­”
            ai_response = get_mock_response(user_message)

        return jsonify({
            'success': True,
            'response': ai_response,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/chat-stream', methods=['POST'])
def chat_stream():
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    GPTå¿œç­”ã‚’å³åº§ã«ç”Ÿæˆãƒ»TTSãƒ»é€ä¿¡ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ã‚’å‘ä¸Š
    """
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        conversation_history = data.get('history', [])
        scenario_id = data.get('scenario_id') or DEFAULT_SCENARIO_ID
        scenario_obj = load_scenario_object(scenario_id)

        def generate():
            """SSE (Server-Sent Events) ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡ï¼ˆTTSä¸¦åˆ—ç”Ÿæˆå¯¾å¿œï¼‰"""
            try:
                # TTSç”Ÿæˆç”¨ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ï¼ˆæœ€å¤§3ä¸¦åˆ—ã§TTSç”Ÿæˆï¼‰
                executor = ThreadPoolExecutor(max_workers=3)
                tts_futures = {}  # {chunk_index: Future}

                def generate_tts_task(chunk_text, chunk_index):
                    """TTSç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œã€ãƒªãƒˆãƒ©ã‚¤å¯¾å¿œï¼‰"""
                    import time
                    tts_start = time.time()

                    # ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆæœ€å¤§3å›ã€æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‰
                    max_retries = 3
                    retry_delay = 0.1  # åˆæœŸé…å»¶100ms

                    for attempt in range(max_retries):
                        try:
                            tts_response = openai_client.audio.speech.create(
                                model="tts-1",
                                voice="nova",
                                input=chunk_text,
                                speed=1.0  # è‡ªç„¶ãªé€Ÿåº¦ã«å¤‰æ›´ï¼ˆ1.1â†’1.0ï¼‰
                            )
                            audio_data = tts_response.content
                            audio_base64 = base64.b64encode(audio_data).decode('utf-8')

                            # TTSç”Ÿæˆæ™‚é–“ã‚’è¨ˆæ¸¬
                            tts_duration = (time.time() - tts_start) * 1000  # ms
                            retry_info = f" (ãƒªãƒˆãƒ©ã‚¤{attempt}å›)" if attempt > 0 else ""
                            print(f"[TTSè¨ˆæ¸¬] ãƒãƒ£ãƒ³ã‚¯{chunk_index}: {tts_duration:.0f}ms ({len(chunk_text)}æ–‡å­—){retry_info}")

                            return {'audio': audio_base64, 'text': chunk_text, 'chunk': chunk_index}
                        except Exception as e:
                            if attempt < max_retries - 1:
                                print(f"[TTS ãƒªãƒˆãƒ©ã‚¤] ãƒãƒ£ãƒ³ã‚¯{chunk_index} è©¦è¡Œ{attempt + 1}/{max_retries}: {e}")
                                time.sleep(retry_delay)
                                retry_delay *= 2  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ100ms â†’ 200ms â†’ 400msï¼‰
                            else:
                                print(f"[TTS æœ€çµ‚ã‚¨ãƒ©ãƒ¼] ãƒãƒ£ãƒ³ã‚¯{chunk_index}: {e} ï¼ˆ{max_retries}å›è©¦è¡Œå¾Œï¼‰")
                                return None

                if not openai_api_key or not openai_client:
                    yield f"data: {json.dumps({'error': 'OpenAI APIæœªè¨­å®š'})}\n\n"
                    return

                # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒã˜ï¼‰
                system_prompt = SALES_ROLEPLAY_PROMPT
                if scenario_obj:
                    persona = scenario_obj.get('persona') or {}
                    # persona_variationsãŒã‚ã‚‹å ´åˆã¯æœ€åˆã®ãƒšãƒ«ã‚½ãƒŠã‚’ä½¿ç”¨ï¼ˆä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ï¼‰
                    if 'persona_variations' in scenario_obj and scenario_obj['persona_variations']:
                        persona = scenario_obj['persona_variations'][0]
                        print(f"[ãƒšãƒ«ã‚½ãƒŠé¸æŠ] {persona.get('variation_name', 'ä¸æ˜')} ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆä¸€è²«æ€§ã®ãŸã‚å›ºå®šï¼‰")

                    guidelines = scenario_obj.get('guidelines') or []
                    persona_txt = []

                    # ãƒšãƒ«ã‚½ãƒŠæƒ…å ±ã‚’è©³ç´°ã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
                    if 'customer_role' in persona:
                        persona_txt.append(f"é¡§å®¢å½¹: {persona['customer_role']}")
                    if 'business_detail' in persona:
                        persona_txt.append(f"äº‹æ¥­è©³ç´°: {persona['business_detail']}")
                    if 'tone' in persona:
                        persona_txt.append(f"ãƒˆãƒ¼ãƒ³ãƒ»æ…‹åº¦: {persona['tone']}")
                    if 'relationship' in persona:
                        persona_txt.append(f"å–¶æ¥­ã¨ã®é–¢ä¿‚æ€§: {persona['relationship']}")
                    if 'knowledge_level' in persona:
                        persona_txt.append(f"çŸ¥è­˜ãƒ¬ãƒ™ãƒ«: {persona['knowledge_level']}")
                    if 'decision_power' in persona:
                        persona_txt.append(f"æ„æ€æ±ºå®šæ¨©: {persona['decision_power']}")
                    if 'current_sns_status' in persona:
                        sns_status = persona['current_sns_status']
                        if isinstance(sns_status, dict):
                            persona_txt.append("ç¾åœ¨ã®SNSé‹ç”¨çŠ¶æ³:")
                            if 'status' in sns_status:
                                persona_txt.append(f"  - çŠ¶æ³: {sns_status['status']}")
                            if 'video_production' in sns_status:
                                persona_txt.append(f"  - å‹•ç”»åˆ¶ä½œ: {sns_status['video_production']}")
                            if 'instagram' in sns_status:
                                persona_txt.append(f"  - Instagram: {sns_status['instagram']}")
                            if 'tiktok' in sns_status:
                                persona_txt.append(f"  - TikTok: {sns_status['tiktok']}")
                            if 'challenges' in sns_status:
                                challenges = sns_status['challenges']
                                if challenges:
                                    persona_txt.append("  - å…·ä½“çš„ãªèª²é¡Œ:")
                                    for challenge in challenges[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
                                        persona_txt.append(f"    â€¢ {challenge}")
                    if 'pain_points' in persona:
                        pain_points = persona['pain_points']
                        if pain_points:
                            persona_txt.append("ãƒšã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ:")
                            for pain in pain_points[:5]:  # æœ€å¤§5ä»¶è¡¨ç¤º
                                persona_txt.append(f"  â€¢ {pain}")
                    if 'budget_sense' in persona:
                        persona_txt.append(f"äºˆç®—æ„Ÿ: {persona['budget_sense']}")

                    if persona_txt:
                        system_prompt += "\n\nã€ã‚·ãƒŠãƒªã‚ªè¨­å®šã€‘\n- " + "\n- ".join(persona_txt)
                    if guidelines:
                        system_prompt += "\n\nã€è¿”ç­”ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘\n- " + "\n- ".join(guidelines)

                # RAGæ¤œç´¢: å®Ÿéš›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—ï¼ˆãƒªã‚¢ãƒ«ãªå¿œç­”ã®ãŸã‚ï¼‰
                try:
                    if RAG_INDEX and RAG_METADATA:
                        # ğŸ¯ è³ªå•ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ï¼ˆãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºï¼‰
                        def extract_question_topics(message: str) -> list:
                            """å–¶æ¥­ã®è³ªå•ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
                            topics = []
                            topic_keywords = {
                                'äºˆç®—': ['äºˆç®—', 'è²»ç”¨', 'ä¾¡æ ¼', 'é‡‘é¡', 'ã‚³ã‚¹ãƒˆ', 'æ–™é‡‘', 'å€¤æ®µ', 'å††', 'ä¸‡å††'],
                                'æœŸé–“': ['æœŸé–“', 'ã„ã¤', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'ç´æœŸ', 'æ™‚é–“', 'ã‚¿ã‚¤ãƒŸãƒ³ã‚°', 'ä»Šã™ã', 'ã™ãã«'],
                                'äº‹ä¾‹': ['äº‹ä¾‹', 'å®Ÿç¸¾', 'ä»–ç¤¾', 'ä¾‹', 'ã‚±ãƒ¼ã‚¹', 'æˆåŠŸä¾‹', 'å°å…¥ä¼æ¥­'],
                                'æ©Ÿèƒ½': ['æ©Ÿèƒ½', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'ã§ãã‚‹', 'å†…å®¹', 'ä»•çµ„ã¿', 'ã‚·ã‚¹ãƒ†ãƒ '],
                                'èª²é¡Œ': ['èª²é¡Œ', 'æ‚©ã¿', 'å›°ã£ã¦', 'å•é¡Œ', 'ä¸å®‰', 'å¿ƒé…', 'æ‡¸å¿µ'],
                                'SNS': ['SNS', 'ã‚¤ãƒ³ã‚¹ã‚¿', 'Instagram', 'TikTok', 'Twitter', 'Facebook', 'ãƒªãƒ¼ãƒ«', 'ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»'],
                                'å‹•ç”»': ['å‹•ç”»', 'ãƒ“ãƒ‡ã‚ª', 'æ˜ åƒ', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'åˆ¶ä½œ', 'æœ¬æ•°', 'æŠ•ç¨¿'],
                                'åŠ¹æœ': ['åŠ¹æœ', 'æˆæœ', 'çµæœ', 'å®Ÿç¸¾', 'æ•°å­—', 'åå¿œ', 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼', 'å†ç”Ÿæ•°'],
                            }
                            for topic, keywords in topic_keywords.items():
                                if any(kw in message for kw in keywords):
                                    topics.append(topic)
                            return topics

                        # å–¶æ¥­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
                        current_topics = extract_question_topics(user_message)

                        # æ¤œç´¢ã‚¯ã‚¨ãƒª: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ + ç›´è¿‘ã®ä¼šè©±ï¼ˆæ–‡è„ˆç²¾åº¦å‘ä¸Šï¼‰+ ãƒˆãƒ”ãƒƒã‚¯å¼·èª¿
                        recent_context = []
                        for msg in conversation_history[-4:]:  # ç›´è¿‘4ä»¶ï¼ˆä¼šè©±ã®æµã‚Œã‚’æŠŠæ¡ï¼‰
                            recent_context.append(f"{msg['speaker']}: {msg['text']}")

                        # ãƒˆãƒ”ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã«è¿½åŠ ï¼ˆé‡ã¿ä»˜ã‘ï¼‰
                        topic_emphasis = ""
                        if current_topics:
                            topic_emphasis = f"\né‡è¦ãƒˆãƒ”ãƒƒã‚¯: {', '.join(current_topics)}"
                            print(f"[RAGæ–‡è„ˆå¼·åŒ–] æ¤œå‡ºãƒˆãƒ”ãƒƒã‚¯: {', '.join(current_topics)}")

                        search_query = "\n".join(recent_context + [f"å–¶æ¥­: {user_message}"]) + topic_emphasis

                        # top_k=10ï¼ˆã‚ˆã‚Šå¤šãã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼‰
                        rag_results = search_rag_patterns(search_query, top_k=10, scenario_id=scenario_id)
                        if rag_results:
                            rag_patterns = []
                            pattern_count = 0
                            similarity_threshold = 0.5  # ğŸ¯ é¡ä¼¼åº¦é–¾å€¤ï¼ˆ0.5ä»¥ä¸Šã®ã¿ä½¿ç”¨ï¼šé«˜å“è³ªä¿è¨¼ï¼‰

                            for result in rag_results:
                                # é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆè·é›¢ãŒå°ã•ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„ï¼šL2è·é›¢ï¼‰
                                similarity = result.get('similarity', 999)
                                if similarity > similarity_threshold:
                                    print(f"[RAGé™¤å¤–] é¡ä¼¼åº¦ãŒä½ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆè·é›¢: {similarity:.3f}ï¼‰")
                                    continue

                                pattern_text = result.get('text', '')
                                if pattern_text and len(pattern_text) < 500:  # ã‚ˆã‚Šè©³ç´°ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨±å®¹
                                    # é¡§å®¢å´ã®ç™ºè¨€ã®ã¿ã‚’æŠ½å‡ºï¼ˆå–¶æ¥­å´ã®ç™ºè¨€ã‚’é™¤å¤–ï¼‰
                                    customer_lines = []
                                    for line in pattern_text.split('\n'):
                                        if line.strip().startswith('é¡§å®¢:'):
                                            customer_lines.append(line.strip())

                                    if customer_lines:
                                        customer_only_text = '\n'.join(customer_lines)
                                        rag_patterns.append(f"- {customer_only_text[:300]}")  # 300æ–‡å­—ã¾ã§ï¼ˆãƒªã‚¢ãƒ«æ„Ÿã‚’ä¿ã¤ï¼‰
                                        pattern_count += 1
                                        print(f"[RAGæ¡ç”¨] ãƒ‘ã‚¿ãƒ¼ãƒ³{pattern_count} (é¡ä¼¼åº¦è·é›¢: {similarity:.3f})")
                                        if pattern_count >= 7:  # æœ€å¤§7ãƒ‘ã‚¿ãƒ¼ãƒ³ã¾ã§ï¼ˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³é‡è¦–ï¼‰
                                            break

                            if rag_patterns:
                                rag_context = "\n\nã€â­ é‡è¦ï¼šå®Ÿéš›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¿…ãšæ´»ç”¨ã™ã‚‹ã“ã¨ï¼‰ã€‘\n"
                                rag_context += "ä»¥ä¸‹ã¯å®Ÿéš›ã®é¡§å®¢ã®å¿œç­”ä¾‹ã§ã™ã€‚ã“ã‚Œã‚‰ã®å£èª¿ã€è¡¨ç¾ã€ãƒ•ã‚£ãƒ©ãƒ¼ï¼ˆã€Œãˆãƒ¼ã¨ã€ã€Œã‚ã®ãƒ¼ã€ã€Œãã†ã§ã™ã­...ã€ãªã©ï¼‰ã€é–“ï¼ˆã€Œ...ã€ï¼‰ã‚’ç©æ¥µçš„ã«ä½¿ã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚\n"
                                rag_context += "**åŒã˜ã‚ˆã†ãªçŠ¶æ³ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚ˆã†ãªè‡ªç„¶ã§ãƒªã‚¢ãƒ«ãªè©±ã—æ–¹ã‚’å¿…ãšçœŸä¼¼ã—ã¦ãã ã•ã„ï¼š**\n\n"
                                rag_context += "\n".join(rag_patterns)
                                rag_context += "\n\nã€å¿œç­”æ™‚ã®æ³¨æ„ã€‘\n"
                                rag_context += "- ä¸Šè¨˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨åŒã˜ã‚ˆã†ãªå£èª¿ãƒ»è¨€ã„å›ã—ã‚’ä½¿ã†ã“ã¨\n"
                                rag_context += "- ãƒ•ã‚£ãƒ©ãƒ¼ï¼ˆã€Œãˆãƒ¼ã¨ã€ã€Œã‚ã®ãƒ¼ã€ã€Œãã†ã§ã™ã­...ã€ï¼‰ã‚’é©åº¦ã«å…¥ã‚Œã‚‹ã“ã¨\n"
                                rag_context += "- é–“ï¼ˆã€Œ...ã€ï¼‰ã‚’ä½¿ã£ã¦è€ƒãˆã¦ã„ã‚‹æ§˜å­ã‚’è¡¨ç¾ã™ã‚‹ã“ã¨\n"
                                rag_context += "- ä¸€èˆ¬çš„ãªå›ç­”ã§ã¯ãªãã€å…·ä½“çš„ã§ãƒªã‚¢ãƒ«ãªè¡¨ç¾ã‚’å¿ƒãŒã‘ã‚‹ã“ã¨"
                                system_prompt += rag_context
                                print(f"[RAGå¼·åŒ–] {len(rag_patterns)}å€‹ã®é¡§å®¢å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚ç…§ï¼ˆå£èª¿ãƒ»è¡¨ç¾ã‚’ç©æ¥µæ´»ç”¨ï¼‰")
                except Exception as e:
                    print(f"[RAG] æ¤œç´¢ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰: {e}")
                    # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œ

                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´æ§‹ç¯‰ï¼ˆç›´è¿‘10ä»¶ï¼šä¼šè©±ã®ä¸€è²«æ€§ã‚’ä¿ã¤ï¼‰
                print(f"[ä¼šè©±å±¥æ­´ãƒ‡ãƒãƒƒã‚°] å—ä¿¡ã—ãŸå±¥æ­´ä»¶æ•°: {len(conversation_history)}")
                for i, msg in enumerate(conversation_history[-10:]):
                    print(f"  å±¥æ­´[{i}] {msg.get('speaker', 'ä¸æ˜')}: {msg.get('text', '')[:50]}...")

                messages = [{"role": "system", "content": system_prompt}]
                for msg in conversation_history[-10:]:
                    if msg['speaker'] == 'å–¶æ¥­':
                        messages.append({"role": "user", "content": msg['text']})
                    elif msg['speaker'] == 'é¡§å®¢':
                        messages.append({"role": "assistant", "content": msg['text']})

                messages.append({"role": "user", "content": user_message})
                print(f"[ä¼šè©±å±¥æ­´ãƒ‡ãƒãƒƒã‚°] GPTã«é€ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)} (systemè¾¼ã¿)")

                # GPT-4o-miniã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ï¼ˆè¶…é«˜é€Ÿï¼‹è‡ªç„¶ãªä¼šè©±ï¼‰
                print("[ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°] GPT-4o-miniå¿œç­”ç”Ÿæˆé–‹å§‹ï¼ˆè¶…é«˜é€Ÿï¼‹è‡ªç„¶ãƒ¢ãƒ¼ãƒ‰ï¼‰")
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",    # è¶…é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ï¼ˆ2-3å€é€Ÿã„ï¼‰
                    messages=messages,
                    max_tokens=1000,        # é©åº¦ãªé•·ã•ã§æ–‡è„ˆã‚’è€ƒæ…®ï¼ˆãƒ†ãƒ³ãƒã¨è³ªã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
                    temperature=0.7,        # ğŸ¯ è‡ªç„¶ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ0.65â†’0.7ï¼šRAGæ´»ç”¨ã¨å‰µé€ æ€§ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
                    stream=True  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹åŒ–
                )

                # ãƒãƒ£ãƒ³ã‚¯ãƒãƒƒãƒ•ã‚¡
                text_buffer = ""
                chunk_count = 0
                first_chunk_sent = False  # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡ã—ãŸã‹ãƒ•ãƒ©ã‚°

                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ï¼ˆTTSä¸¦åˆ—ç”Ÿæˆï¼‰
                sentence_count = 0  # æ–‡æ•°ã‚«ã‚¦ãƒ³ãƒˆ
                next_yield_index = 1  # æ¬¡ã«yieldã™ã¹ããƒãƒ£ãƒ³ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

                for chunk in response:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        text_buffer += content

                        # ChatGPTé¢¨ï¼šæœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã¯å³åº§ã«é€ä¿¡ã€2ãƒãƒ£ãƒ³ã‚¯ç›®ä»¥é™ã¯é€šå¸¸ãƒ«ãƒ¼ãƒ«
                        should_send = False
                        delimiter = ''

                        if not first_chunk_sent:
                            # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã¯è¶…æ—©ã‚ã«é€ä¿¡ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½“æ„Ÿé€Ÿåº¦å‘ä¸Šï¼‰
                            if 'ã€‚' in text_buffer and len(text_buffer) >= 3:
                                # å¥ç‚¹ãŒã‚ã‚Šã€3æ–‡å­—ä»¥ä¸Šãªã‚‰å³é€ä¿¡
                                should_send = True
                                delimiter = 'ã€‚'
                            elif 'ã€' in text_buffer and len(text_buffer) >= 8:
                                # èª­ç‚¹ã¯8æ–‡å­—ä»¥ä¸Šã§é€ä¿¡
                                should_send = True
                                delimiter = 'ã€'
                            elif len(text_buffer) >= 60:
                                # å¥èª­ç‚¹ãªã—ã®å ´åˆã¯60æ–‡å­—ã¾ã§å¾…ã¤ï¼ˆå˜èªã®é€”ä¸­ã§åˆ‡ã‚‰ãªã„ãŸã‚ï¼‰
                                # åŠ©è©ã®ä½ç½®ã§åˆ‡ã‚‹
                                particles = ['ã£ã¦', 'ã‘ã©', 'ã‹ã‚‰', 'ã®ã§', 'ã‚“ã§', 'ãŒ', 'ã§', 'ã‚’', 'ã«', 'ã¯', 'ã‚‚', 'ã¨', 'ã‚„', 'ã¦']
                                best_pos = -1
                                for particle in particles:
                                    pos = text_buffer.rfind(particle)
                                    if pos > best_pos and pos >= 15:  # æœ€ä½15æ–‡å­—ã¯å¿…è¦
                                        best_pos = pos + len(particle)
                                if best_pos > 0:
                                    should_send = True
                                    delimiter = 'particle'  # åŠ©è©ã§åˆ‡ã‚‹ã“ã¨ã‚’ç¤ºã™ç‰¹æ®Šãƒ•ãƒ©ã‚°
                        else:
                            # 2ãƒãƒ£ãƒ³ã‚¯ç›®ä»¥é™ã‚‚ç´°ã‹ãåˆ†å‰²
                            if 'ã€‚' in text_buffer and len(text_buffer) >= 5:
                                # å¥ç‚¹ãŒã‚ã‚Šã€5æ–‡å­—ä»¥ä¸Šãªã‚‰é€ä¿¡
                                should_send = True
                                delimiter = 'ã€‚'
                            elif 'ã€' in text_buffer and len(text_buffer) >= 12:
                                # èª­ç‚¹ã§ã‚‚12æ–‡å­—ä»¥ä¸Šæºœã¾ã£ãŸã‚‰é€ä¿¡
                                should_send = True
                                delimiter = 'ã€'
                            elif len(text_buffer) >= 60:
                                # å¥èª­ç‚¹ãªã—ã®å ´åˆã¯60æ–‡å­—ã¾ã§å¾…ã¤ï¼ˆå˜èªã®é€”ä¸­ã§åˆ‡ã‚‰ãªã„ãŸã‚ï¼‰
                                # åŠ©è©ã®ä½ç½®ã§åˆ‡ã‚‹
                                particles = ['ã£ã¦', 'ã‘ã©', 'ã‹ã‚‰', 'ã®ã§', 'ã‚“ã§', 'ãŒ', 'ã§', 'ã‚’', 'ã«', 'ã¯', 'ã‚‚', 'ã¨', 'ã‚„', 'ã¦']
                                best_pos = -1
                                for particle in particles:
                                    pos = text_buffer.rfind(particle)
                                    if pos > best_pos and pos >= 15:  # æœ€ä½15æ–‡å­—ã¯å¿…è¦
                                        best_pos = pos + len(particle)
                                if best_pos > 0:
                                    should_send = True
                                    delimiter = 'particle'  # åŠ©è©ã§åˆ‡ã‚‹ã“ã¨ã‚’ç¤ºã™ç‰¹æ®Šãƒ•ãƒ©ã‚°

                        if should_send:
                            if delimiter == 'particle':
                                # åŠ©è©ã®ä½ç½®ã§åˆ‡ã‚‹ï¼ˆç‰¹æ®Šå‡¦ç†ï¼‰
                                particles = ['ã£ã¦', 'ã‘ã©', 'ã‹ã‚‰', 'ã®ã§', 'ã‚“ã§', 'ãŒ', 'ã§', 'ã‚’', 'ã«', 'ã¯', 'ã‚‚', 'ã¨', 'ã‚„', 'ã¦']
                                best_pos = -1
                                for particle in particles:
                                    pos = text_buffer.rfind(particle)
                                    if pos > best_pos and pos >= 15:
                                        best_pos = pos + len(particle)

                                if best_pos > 0:
                                    chunk_text = text_buffer[:best_pos].strip()
                                    chunk_count += 1
                                    print(f"[ãƒãƒ£ãƒ³ã‚¯{chunk_count}] {chunk_text} ï¼ˆåŠ©è©ã§åˆ†å‰²ãƒ»TTSä¸¦åˆ—ç”Ÿæˆé–‹å§‹ï¼‰")

                                    # TTSç”Ÿæˆã‚’ä¸¦åˆ—å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
                                    future = executor.submit(generate_tts_task, chunk_text, chunk_count)
                                    tts_futures[chunk_count] = future

                                    text_buffer = text_buffer[best_pos:]
                                    first_chunk_sent = True
                            elif delimiter:
                                # å¥èª­ç‚¹ã§åˆ†å‰²
                                chunks = text_buffer.split(delimiter)
                                # æœ€å¾Œã®è¦ç´ ï¼ˆæœªå®Œæˆã®æ–‡ï¼‰ã‚’é™¤ã„ã¦å‡¦ç†
                                for part in chunks[:-1]:
                                    if part.strip():
                                        chunk_text = part.strip() + delimiter
                                        chunk_count += 1
                                        print(f"[ãƒãƒ£ãƒ³ã‚¯{chunk_count}] {chunk_text} ï¼ˆTTSä¸¦åˆ—ç”Ÿæˆé–‹å§‹ï¼‰")

                                        # TTSç”Ÿæˆã‚’ä¸¦åˆ—å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
                                        future = executor.submit(generate_tts_task, chunk_text, chunk_count)
                                        tts_futures[chunk_count] = future

                                # æœªå®Œæˆã®æ–‡ã‚’ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã™
                                text_buffer = chunks[-1]
                                first_chunk_sent = True
                            else:
                                # delimiter ãŒ None ã®å ´åˆï¼ˆã“ã®ã‚±ãƒ¼ã‚¹ã¯ã‚‚ã†ç™ºç”Ÿã—ãªã„ã¯ãšï¼‰
                                chunk_text = text_buffer.strip()
                                chunk_count += 1
                                print(f"[ãƒãƒ£ãƒ³ã‚¯{chunk_count}] {chunk_text} ï¼ˆTTSä¸¦åˆ—ç”Ÿæˆé–‹å§‹ï¼‰")

                                # TTSç”Ÿæˆã‚’ä¸¦åˆ—å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
                                future = executor.submit(generate_tts_task, chunk_text, chunk_count)
                                tts_futures[chunk_count] = future

                                text_buffer = ""
                                first_chunk_sent = True

                    # å®Œæˆã—ãŸTTSã‹ã‚‰é †åºé€šã‚Šã«yieldï¼ˆGPTã‚¹ãƒˆãƒªãƒ¼ãƒ å—ä¿¡ã¨ä¸¦åˆ—å®Ÿè¡Œï¼‰
                    while next_yield_index in tts_futures:
                        future = tts_futures[next_yield_index]
                        if future.done():
                            result = future.result()
                            if result:
                                yield f"data: {json.dumps(result)}\n\n"
                                if not first_chunk_sent:
                                    first_chunk_sent = True
                                print(f"[ãƒãƒ£ãƒ³ã‚¯{next_yield_index}] é€ä¿¡å®Œäº†ï¼ˆä¸¦åˆ—ç”Ÿæˆï¼‰")
                            del tts_futures[next_yield_index]
                            next_yield_index += 1
                        else:
                            break  # ã¾ã å®Œæˆã—ã¦ã„ãªã„ã®ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

                # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
                if text_buffer.strip():
                    chunk_count += 1
                    print(f"[æœ€çµ‚ãƒãƒ£ãƒ³ã‚¯{chunk_count}] {text_buffer} ï¼ˆTTSä¸¦åˆ—ç”Ÿæˆé–‹å§‹ï¼‰")
                    future = executor.submit(generate_tts_task, text_buffer.strip(), chunk_count)
                    tts_futures[chunk_count] = future

                # å…¨ã¦ã®TTSç”Ÿæˆå®Œäº†ã‚’å¾…ã¡ã€é †åºé€šã‚Šã«yield
                while next_yield_index <= chunk_count:
                    if next_yield_index in tts_futures:
                        future = tts_futures[next_yield_index]
                        result = future.result()  # å®Œäº†ã‚’å¾…ã¤
                        if result:
                            if next_yield_index == chunk_count:
                                result['final'] = True  # æœ€çµ‚ãƒãƒ£ãƒ³ã‚¯ãƒãƒ¼ã‚¯
                            yield f"data: {json.dumps(result)}\n\n"
                            print(f"[ãƒãƒ£ãƒ³ã‚¯{next_yield_index}] é€ä¿¡å®Œäº†ï¼ˆæœ€çµ‚å‡¦ç†ï¼‰")
                        del tts_futures[next_yield_index]
                    next_yield_index += 1

                # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                executor.shutdown(wait=False)

                print(f"[ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†] åˆè¨ˆ{chunk_count}ãƒãƒ£ãƒ³ã‚¯é€ä¿¡")

            except Exception as e:
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'error': str(e)})}\n\n"

        return Response(generate(), mimetype='text/event-stream', headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


def get_mock_response(user_message):
    """ãƒ¢ãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆ"""
    mock_responses = [
        "ã“ã‚“ã«ã¡ã¯ï¼ãŠå¿™ã—ã„ä¸­ãŠæ™‚é–“ã‚’ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã©ã®ã‚ˆã†ãªã”ç›¸è«‡ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
        "ãªã‚‹ã»ã©ã€èˆˆå‘³æ·±ã„ã§ã™ã­ã€‚è©³ã—ãæ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ",
        "ç¢ºã‹ã«ãã®é€šã‚Šã§ã™ã­ã€‚ä»–ã«ã‚‚æ°—ã«ãªã‚‹ç‚¹ã¯ã”ã–ã„ã¾ã™ã‹ï¼Ÿ",
        "ã¨ã¦ã‚‚è‰¯ã„ææ¡ˆã ã¨æ€ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã©ã®ã‚ˆã†ãªå†…å®¹ã§ã—ã‚‡ã†ã‹ï¼Ÿ",
        "ãã‚Œã¯ç´ æ™´ã‚‰ã—ã„ã§ã™ã­ã€‚ãœã²æ¤œè¨ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚"
    ]
    
    if "ã“ã‚“ã«ã¡ã¯" in user_message or "ã¯ã˜ã‚ã¾ã—ã¦" in user_message:
        return mock_responses[0]
    elif "è³ªå•" in user_message or "æ•™ãˆã¦" in user_message:
        return mock_responses[1]
    elif "ææ¡ˆ" in user_message or "ã‚µãƒ¼ãƒ“ã‚¹" in user_message:
        return mock_responses[3]
    else:
        return mock_responses[1]

@app.route('/api/tts', methods=['POST'])
def text_to_speech():
    """OpenAI TTSã‚’ä½¿ç”¨ã—ãŸéŸ³å£°åˆæˆ"""
    try:
        data = request.get_json()
        text = data.get('text', '')
        voice = data.get('voice', 'nova')  # ã‚¢ãƒã‚¿ãƒ¼ã«å¿œã˜ãŸéŸ³å£°IDï¼ˆæ—¥æœ¬èªã«é©ã—ãŸå¥³æ€§å£°ï¼‰

        if not text:
            return jsonify(success=False, error='ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™'), 400

        if not openai_client:
            return jsonify(success=False, error='OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæœªåˆæœŸåŒ–'), 500

        # æœ‰åŠ¹ãªéŸ³å£°IDã®ãƒã‚§ãƒƒã‚¯
        valid_voices = ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
        if voice not in valid_voices:
            voice = 'alloy'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        # OpenAI TTSã§éŸ³å£°ç”Ÿæˆï¼ˆé«˜å“è³ªãƒ¢ãƒ‡ãƒ« + ãƒªã‚¢ãƒ«ãªä¼šè©±ã‚¹ãƒ”ãƒ¼ãƒ‰ï¼‰
        response = openai_client.audio.speech.create(
            model="tts-1",  # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹é‡è¦–ï¼‰  # é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ˆã‚Šè‡ªç„¶ãªç™ºéŸ³ï¼‰
            voice=voice,       # ã‚¢ãƒã‚¿ãƒ¼ã«å¿œã˜ãŸéŸ³å£°ï¼ˆalloy, echo, fable, onyx, nova, shimmerï¼‰
            input=text,
            speed=1.3          # ãƒªã‚¢ãƒ«ãªå–¶æ¥­ãƒ­ãƒ¼ãƒ—ãƒ¬ã®ãƒšãƒ¼ã‚¹ï¼ˆ1-2ç§’ã§è¿”ç­”é–‹å§‹ï¼‰
        )

        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        audio_data = response.content
        return Response(audio_data, mimetype='audio/mpeg')

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify(success=False, error=str(e)), 500


@app.route('/api/did-video', methods=['POST'])
def generate_did_video():
    """
    D-ID APIã‚’ä½¿ç”¨ã—ã¦ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ã‚’ç”Ÿæˆï¼ˆWeek 7: ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°å¯¾å¿œï¼‰

    Request:
        {
            "text": "ã“ã‚“ã«ã¡ã¯",
            "avatar_url": "https://...",  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¢ãƒã‚¿ãƒ¼ç”»åƒURL
            "voice_id": "ja-JP-NanamiNeural"  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: éŸ³å£°ID
        }

    Response:
        {
            "success": true,
            "video_url": "https://...",
            "cached": true|false,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‹ã©ã†ã‹
            "talk_id": "..."  # æ–°è¦ç”Ÿæˆæ™‚ã®ã¿
        }
    """
    try:
        data = request.json
        text = data.get('text', '')
        avatar_url = data.get('avatar_url', 'https://d-id-public-bucket.s3.amazonaws.com/alice.jpg')
        voice_id = data.get('voice_id', 'ja-JP-NanamiNeural')

        if not text:
            return jsonify(success=False, error='ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ã§ã™'), 400

        # Week 7: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        cache_key = generate_cache_key(text, voice_id, avatar_url)

        # Week 7: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
        if supabase_client:
            cached_video = get_cached_video(supabase_client, cache_key)
            if cached_video:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼å³åº§ã«è¿”å´
                return jsonify(
                    success=True,
                    video_url=cached_video['video_url'],
                    cached=True,
                    cache_hit_count=cached_video.get('hit_count', 0)
                )

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼šD-IDã§æ–°è¦ç”Ÿæˆ
        did_client = get_did_client()
        if not did_client:
            return jsonify(success=False, error='D-ID APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'), 500

        # D-IDå‹•ç”»ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥ï¼‰
        print(f"ğŸ¬ Generating D-ID video for text: {text[:50]}...")
        result = did_client.create_talk_from_text(
            text=text,
            voice_id=voice_id,
            source_url=avatar_url
        )

        talk_id = result.get('id')
        print(f"ğŸ“ D-ID talk created: {talk_id}")

        # å®Œäº†ã‚’å¾…æ©Ÿï¼ˆæœ€å¤§120ç§’ï¼‰
        did_video_url = did_client.wait_for_completion(talk_id, timeout=120)

        if did_video_url:
            print(f"âœ… D-ID video ready: {did_video_url}")

            # Week 7: Supabase Storageã«ä¿å­˜ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            if supabase_client:
                storage_url = download_video_to_storage(supabase_client, did_video_url, cache_key)
                if storage_url:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
                    save_video_to_cache(
                        supabase_client,
                        cache_key=cache_key,
                        text=text,
                        voice_id=voice_id,
                        avatar_url=avatar_url,
                        video_url=storage_url,
                        storage_path=f"video_cache/{cache_key}.mp4"
                    )
                    # Supabase Storageã® URL ã‚’è¿”ã™
                    final_video_url = storage_url
                else:
                    # Storageä¿å­˜å¤±æ•—æ™‚ã¯D-IDã®URLã‚’ãã®ã¾ã¾ä½¿ç”¨
                    final_video_url = did_video_url
            else:
                final_video_url = did_video_url

            return jsonify(
                success=True,
                video_url=final_video_url,
                cached=False,
                talk_id=talk_id
            )
        else:
            return jsonify(
                success=False,
                error='å‹•ç”»ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ',
                talk_id=talk_id
            ), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify(success=False, error=str(e)), 500


@app.route('/api/transcribe', methods=['POST'])
def transcribe():
    try:
        if 'audio' not in request.files:
            return jsonify(success=False, error='éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'), 400
        up = request.files['audio']
        # ä¸€æ—¦ .bin ã§ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.bin') as t:
            up.save(t.name)
            temp_path = t.name
        # å…ˆé ­ãƒã‚¤ãƒˆã‹ã‚‰å®Ÿä½“ã‚’åˆ¤å®šã—ã¦rename
        real_suffix = sniff_suffix(temp_path)
        new_path = temp_path
        if real_suffix != '.bin':
            new_path = temp_path + real_suffix
            os.replace(temp_path, new_path)
        size = os.path.getsize(new_path)
        print(f"[upload] mime={up.mimetype} saved={new_path} size={size}")
        if size < 1024:  # 1KBæœªæº€ã¯æ˜ã‚‰ã‹ã«çŸ­ã™ãã‚‹
            try: os.remove(new_path)
            except Exception: pass
            print(f"[ã‚¨ãƒ©ãƒ¼] éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {size} bytes")
            return jsonify(success=False, error=f'éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™({size} bytes)ã€‚ã‚‚ã†å°‘ã—é•·ãè©±ã—ã¦ãã ã•ã„ã€‚'), 400
        # Whisperã¸ï¼ˆã¾ãšç›´é€ï¼‰
        if not openai_client:
            return jsonify(success=False, error='OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæœªåˆæœŸåŒ–'), 500
        try:
            with open(new_path, 'rb') as f:
                r = openai_client.audio.transcriptions.create(
                    model='whisper-1',
                    file=f,
                    language='ja'
                )
            text = (getattr(r, 'text', '') or '').strip()
            print(f"[WhisperæˆåŠŸ] èªè­˜çµæœ: {text}")
            return jsonify(success=True, text=text, method='whisper', timestamp=datetime.now().isoformat())
        except Exception as e:
            print(f"[Whisperå¤±æ•—] ã‚¨ãƒ©ãƒ¼: {e}, ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size} bytes")
            if not (PYDUB_AVAILABLE and FFMPEG_AVAILABLE):
                raise
            wav_path = new_path + '.wav'
            AudioSegment.from_file(new_path).set_frame_rate(16000).set_channels(1).export(wav_path, format='wav')
            try:
                with open(wav_path, 'rb') as f:
                    r = openai_client.audio.transcriptions.create(
                        model='whisper-1',
                        file=f,
                        language='ja'
                    )
                text = (getattr(r, 'text', '') or '').strip()
                return jsonify(success=True, text=text, method='whisper', timestamp=datetime.now().isoformat())
            finally:
                try: os.remove(wav_path)
                except Exception: pass
    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify(success=False, error=str(e)), 500
    finally:
        try:
            if 'new_path' in locals() and new_path and os.path.exists(new_path):
                os.remove(new_path)
        except Exception:
            pass

def transcribe_with_whisper(audio_bytes):
    """Whisper APIã‚’ä½¿ç”¨ã—ãŸéŸ³å£°èªè­˜"""
    try:
        print(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(audio_bytes)} bytes")
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_file.write(audio_bytes)
            temp_file_path = temp_file.name
        
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {temp_file_path}")
        
        try:
            # pydubãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if not PYDUB_AVAILABLE:
                raise Exception("pydubãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ffmpegã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€MP3ã«å¤‰æ›ï¼ˆWhisperã®æ¨å¥¨å½¢å¼ï¼‰
            print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›é–‹å§‹...")
            audio = AudioSegment.from_wav(temp_file_path)
            mp3_path = temp_file_path.replace('.wav', '.mp3')
            audio.export(mp3_path, format="mp3")
            print(f"MP3å¤‰æ›å®Œäº†: {mp3_path}")
            
            # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
            if not openai_client:
                raise Exception("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            print("Whisper APIå‘¼ã³å‡ºã—é–‹å§‹...")
            # Whisper APIã§éŸ³å£°èªè­˜ï¼ˆæ–°ã—ã„APIå½¢å¼ï¼‰
            with open(mp3_path, 'rb') as audio_file:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ja"  # æ—¥æœ¬èªæŒ‡å®š
                )
            
            transcribed_text = transcript.text.strip()
            print(f"éŸ³å£°èªè­˜çµæœ: {transcribed_text}")
            
            return jsonify({
                'success': True,
                'text': transcribed_text,
                'method': 'whisper',
                'timestamp': datetime.now().isoformat()
            })
            
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            for file_path in [temp_file_path, mp3_path]:
                if os.path.exists(file_path):
                    os.unlink(file_path)
                    print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {file_path}")
                    
    except Exception as e:
        print(f"WhisperéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'WhisperéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}'
        }), 500

def transcribe_with_whisper_file(input_file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰Whisper APIã‚’ä½¿ç”¨ï¼ˆç›´é€â†’å¤±æ•—æ™‚ã«WAVã¸å¤‰æ›ã—ã¦å†é€ï¼‰"""
    mp3_path = None
    try:
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {input_file_path}")
        size = os.path.getsize(input_file_path)
        print(f"å—ä¿¡ã‚µã‚¤ã‚º: {size} bytes")
        if size < 2048:
            raise Exception("éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™ï¼ˆ2KBæœªæº€ï¼‰")

        if not openai_client:
            raise Exception("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # 1) ã¾ãšã¯ãã®ã¾ã¾Whisperã¸
        try:
            print("Whisperã¸ç›´æ¥é€ä¿¡...")
            with open(input_file_path, 'rb') as f:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ja"
                )
        except Exception as direct_err:
            print(f"ç›´æ¥é€ä¿¡å¤±æ•—: {direct_err}")
            if not PYDUB_AVAILABLE or not FFMPEG_AVAILABLE:
                raise
            print("pydubã§WAV(16k,mono)ã¸å¤‰æ›ã—ã¦å†é€...")
            audio = AudioSegment.from_file(input_file_path)
            wav_path = input_file_path + '.wav'
            audio.set_frame_rate(16000).set_channels(1).export(wav_path, format='wav')
            with open(wav_path, 'rb') as f:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ja"
                )
            try:
                os.remove(wav_path)
            except Exception:
                pass

        text = (transcript.text or '').strip()
        print(f"éŸ³å£°èªè­˜çµæœ: {text}")
        return jsonify({'success': True, 'text': text, 'method': 'whisper', 'timestamp': datetime.now().isoformat()})

    except Exception as e:
        print(f"WhisperéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        import traceback; traceback.print_exc()
        return jsonify({'success': False, 'error': f'WhisperéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}'}), 500
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for file_path in [input_file_path, mp3_path] if 'mp3_path' in locals() else [input_file_path]:
            if file_path and os.path.exists(file_path):
                try:
                    os.unlink(file_path)
                    print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {file_path}")
                except Exception:
                    pass

# GeminiéŸ³å£°èªè­˜é–¢æ•°ã¯å‰Šé™¤ï¼ˆWhisperçµ±ä¸€ç‰ˆã®ãŸã‚ï¼‰

@app.route('/api/evaluate', methods=['POST'])
def evaluate_conversation():
    try:
        data = request.get_json()
        conversation = data.get('conversation', [])
        scenario_id = data.get('scenario_id')  # ã‚·ãƒŠãƒªã‚ªIDã‚’å–å¾—

        # å–¶æ¥­ã®ç™ºè¨€ã®ã¿ã‚’æŠ½å‡º
        sales_utterances = [msg['text'] for msg in conversation if msg['speaker'] == 'å–¶æ¥­']

        if not sales_utterances:
            return jsonify({
                'success': False,
                'error': 'å–¶æ¥­ã®ç™ºè¨€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 400

        # è¬›è©•ç”Ÿæˆï¼ˆWeek 5æ”¹å–„ç‰ˆ: ã‚·ãƒŠãƒªã‚ªåˆ¥Few-shotå¯¾å¿œï¼‰
        evaluation = generate_evaluation_with_gpt4(sales_utterances, scenario_id)

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: è©•ä¾¡çµæœã‚’å‡ºåŠ›
        print("\n" + "="*80)
        print("[è©•ä¾¡çµæœãƒ‡ãƒãƒƒã‚°]")
        print(f"overall: {evaluation.get('overall', 'N/A')}")
        print(f"strengths: {evaluation.get('strengths', 'N/A')}")
        print(f"improvements: {evaluation.get('improvements', 'N/A')}")
        print(f"scores: {evaluation.get('scores', 'N/A')}")
        print("="*80 + "\n")

        return jsonify({
            'success': True,
            'evaluation': evaluation,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def generate_evaluation_with_gpt4(sales_utterances, scenario_id=None):
    """GPT-4ã‚’ä½¿ç”¨ã—ãŸå–¶æ¥­ã‚¹ã‚­ãƒ«è©•ä¾¡ï¼ˆWeek 5æ”¹å–„ç‰ˆ: ã‚·ãƒŠãƒªã‚ªåˆ¥Few-shotå¯¾å¿œï¼‰"""
    try:
        # å–¶æ¥­ã®ç™ºè¨€ã‚’çµåˆ
        sales_text = " ".join(sales_utterances)

        # ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã¨Few-shotã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        scenario_context = ""
        few_shot_examples = ""

        if scenario_id:
            # ã‚·ãƒŠãƒªã‚ªæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
            scenario_obj = load_scenario_object(scenario_id)
            if scenario_obj:
                scenario_title = scenario_obj.get('title', '')
                scenario_context = f"\nã€ã‚·ãƒŠãƒªã‚ªã€‘: {scenario_title}\n"
                scenario_context += f"ã€ã‚·ãƒŠãƒªã‚ªã®é‡ç‚¹è©•ä¾¡é …ç›®ã€‘:\n"
                persona = scenario_obj.get('persona', {})
                if persona:
                    scenario_context += f"- ç›¸è«‡è€…ã®çŠ¶æ…‹: {persona.get('tone', '')} ({persona.get('relationship', '')})\n"

            # Few-shotã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã‚€
            samples_data = load_evaluation_samples(scenario_id)
            if samples_data:
                eval_focus = samples_data.get('evaluation_focus', [])
                if eval_focus:
                    scenario_context += "- è©•ä¾¡ã®é‡ç‚¹: " + ", ".join(eval_focus) + "\n"

                # Few-shotã‚µãƒ³ãƒ—ãƒ«ã‚’æ§‹ç¯‰ï¼ˆè‰¯ã„ä¾‹1ä»¶ã€æ‚ªã„ä¾‹1ä»¶ï¼‰
                examples = samples_data.get('few_shot_examples', [])
                good_examples = [ex for ex in examples if ex.get('quality') == 'good']
                poor_examples = [ex for ex in examples if ex.get('quality') == 'poor']

                if good_examples:
                    good_ex = good_examples[0]  # æœ€åˆã®è‰¯ã„ä¾‹ã‚’ä½¿ç”¨
                    few_shot_examples += "\nã€è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«1ï¼šè‰¯ã„ä¾‹ã€‘\n"
                    few_shot_examples += "å–¶æ¥­ã®ç™ºè¨€: " + " â†’ ".join(good_ex['conversation'][::2][:3]) + "...\n"
                    few_shot_examples += f"è©•ä¾¡ã‚¹ã‚³ã‚¢: è³ªå•åŠ›={good_ex['evaluation']['scores']['questioning_skill']}, "
                    few_shot_examples += f"å‚¾è´åŠ›={good_ex['evaluation']['scores']['listening_skill']}, "
                    few_shot_examples += f"ææ¡ˆåŠ›={good_ex['evaluation']['scores']['proposal_skill']}, "
                    few_shot_examples += f"ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°={good_ex['evaluation']['scores']['closing_skill']}\n"
                    few_shot_examples += f"è©•ä¾¡ç†ç”±: {good_ex['evaluation']['strengths'][0]}\n"

                if poor_examples:
                    poor_ex = poor_examples[0]  # æœ€åˆã®æ‚ªã„ä¾‹ã‚’ä½¿ç”¨
                    few_shot_examples += "\nã€è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«2ï¼šæ”¹å–„ãŒå¿…è¦ãªä¾‹ã€‘\n"
                    few_shot_examples += "å–¶æ¥­ã®ç™ºè¨€: " + " â†’ ".join(poor_ex['conversation'][::2][:3]) + "...\n"
                    few_shot_examples += f"è©•ä¾¡ã‚¹ã‚³ã‚¢: è³ªå•åŠ›={poor_ex['evaluation']['scores']['questioning_skill']}, "
                    few_shot_examples += f"å‚¾è´åŠ›={poor_ex['evaluation']['scores']['listening_skill']}, "
                    few_shot_examples += f"ææ¡ˆåŠ›={poor_ex['evaluation']['scores']['proposal_skill']}, "
                    few_shot_examples += f"ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°={poor_ex['evaluation']['scores']['closing_skill']}\n"
                    few_shot_examples += f"è©•ä¾¡ç†ç”±: {poor_ex['evaluation']['improvements'][0]}\n"

        # Rubricã‹ã‚‰è©•ä¾¡åŸºæº–ã‚’æ§‹ç¯‰
        rubric_description = ""
        if RUBRIC_DATA and 'evaluation_criteria' in RUBRIC_DATA:
            criteria_list = []
            for criterion in RUBRIC_DATA['evaluation_criteria']:
                name = criterion.get('name', '')
                desc = criterion.get('description', '')
                criteria_list.append(f"- {name}: {desc}")
            rubric_description = "\n".join(criteria_list)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“ç‰ˆ
            rubric_description = """- è³ªå•åŠ›: é¡§å®¢ã®ãƒ‹ãƒ¼ã‚ºãƒ»èª²é¡Œã‚’é©åˆ‡ã«å¼•ãå‡ºã™è³ªå•
- å‚¾è´åŠ›: ç›¸æ‰‹ã®ç™ºè¨€ã‚’ç†è§£ã—ã€é©åˆ‡ã«å—å®¹ãƒ»å…±æ„Ÿ
- ææ¡ˆåŠ›: é¡§å®¢ã®èª²é¡Œã«å¯¾ã™ã‚‹å…·ä½“çš„ãªè§£æ±ºç­–ã‚’æç¤º
- ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°åŠ›: æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»æ±ºå®šã‚’ä¿ƒã™é©åˆ‡ãªã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°"""

        # GPT-4ã§è©•ä¾¡ã‚’ç”Ÿæˆï¼ˆFew-shotå¯¾å¿œãƒ»å…·ä½“çš„ãªè¬›è©•ç”Ÿæˆï¼‰
        evaluation_prompt = f"""
        ã‚ãªãŸã¯ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»åˆ¶ä½œå–¶æ¥­ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã®å–¶æ¥­ã®ç™ºè¨€ã‚’åˆ†æã—ã¦ã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªè©•ä¾¡ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

        {scenario_context}
        ã€å–¶æ¥­ã®ç™ºè¨€ã€‘
        {sales_text}

        ã€è©•ä¾¡é …ç›®ã€‘ï¼ˆ5ç‚¹æº€ç‚¹ã§è©•ä¾¡ï¼‰
        {rubric_description}

        ã€ç‚¹æ•°åŸºæº–ã€‘
        5ç‚¹: éå¸¸ã«å„ªã‚Œã¦ã„ã‚‹ï¼ˆãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ã€æ¨¡ç¯„çš„ï¼‰
        4ç‚¹: å„ªã‚Œã¦ã„ã‚‹ï¼ˆååˆ†ãªã‚¹ã‚­ãƒ«ã€ã‚ãšã‹ãªæ”¹å–„ä½™åœ°ï¼‰
        3ç‚¹: å¹³å‡çš„ï¼ˆåŸºæœ¬ã¯ã§ãã¦ã„ã‚‹ãŒã€æ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼‰
        2ç‚¹: è¦æ”¹å–„ï¼ˆåŸºæœ¬ã‚¹ã‚­ãƒ«ãŒä¸è¶³ã€é‡è¦ãªæ”¹å–„ç‚¹ã‚ã‚Šï¼‰
        1ç‚¹: å¤§å¹…ãªæ”¹å–„ãŒå¿…è¦ï¼ˆã‚¹ã‚­ãƒ«ãŒã»ã¨ã‚“ã©ç™ºæ®ã•ã‚Œã¦ã„ãªã„ï¼‰

        {few_shot_examples}

        ã€é‡è¦ãªè©•ä¾¡æŒ‡é‡ã€‘
        1. **è‰¯ã‹ã£ãŸç‚¹**ã¯å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ã¦è©•ä¾¡ã™ã‚‹
           ä¾‹: ã€Œã€ã©ã®ã‚ˆã†ãªèª²é¡Œã‚’ãŠæŒã¡ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã§ã€é¡§å®¢ã®ãƒ‹ãƒ¼ã‚ºã‚’å¹…åºƒãèãå‡ºã›ã¦ã„ã¾ã™ã€

        2. **æ”¹å–„ç‚¹**ã‚‚å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ã€ã©ã†æ”¹å–„ã™ã¹ãã‹æ˜ç¤ºã™ã‚‹
           ä¾‹: ã€Œã€ã†ã¡ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯æœˆ5ä¸‡å††ã§ã™ã€ã¨ä¾¡æ ¼ã‚’å…ˆã«æç¤ºã—ã¦ã„ã¾ã™ãŒã€ã¾ãšé¡§å®¢ã®äºˆç®—æ„Ÿã‚’ãƒ’ã‚¢ãƒªãƒ³ã‚°ã—ã¦ã‹ã‚‰ææ¡ˆã™ã‚‹ã¨åŠ¹æœçš„ã§ã™ã€

        3. **ä¼šè©±ã®æµã‚Œ**ã‚’æ™‚ç³»åˆ—ã§åˆ†æã™ã‚‹ï¼ˆæŒ¨æ‹¶â†’ãƒ’ã‚¢ãƒªãƒ³ã‚°â†’ææ¡ˆâ†’ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰

        4. **è©•ä¾¡ã¯å³ã—ãã€å…·ä½“çš„ã«**ï¼ˆæ›–æ˜§ãªè¤’ã‚è¨€è‘‰ã¯é¿ã‘ã‚‹ï¼‰

        ä¸Šè¨˜ã®æŒ‡é‡ã«å¾“ã£ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§è©•ä¾¡ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
        {{
            "scores": {{
                "questioning": æ•°å€¤ï¼ˆ1-5ï¼‰,
                "listening": æ•°å€¤ï¼ˆ1-5ï¼‰,
                "proposing": æ•°å€¤ï¼ˆ1-5ï¼‰,
                "closing": æ•°å€¤ï¼ˆ1-5ï¼‰,
                "total": æ•°å€¤ï¼ˆ4é …ç›®ã®åˆè¨ˆï¼‰
            }},
            "strengths": [
                "ã€è³ªå•åŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸè‰¯ã‹ã£ãŸç‚¹",
                "ã€å‚¾è´åŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸè‰¯ã‹ã£ãŸç‚¹",
                "ã€ææ¡ˆåŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸè‰¯ã‹ã£ãŸç‚¹"
            ],
            "improvements": [
                "ã€è³ªå•åŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸæ”¹å–„ç‚¹ã¨æ”¹å–„æ–¹æ³•",
                "ã€å‚¾è´åŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸæ”¹å–„ç‚¹ã¨æ”¹å–„æ–¹æ³•",
                "ã€ææ¡ˆåŠ›ã€‘å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãŸæ”¹å–„ç‚¹ã¨æ”¹å–„æ–¹æ³•"
            ],
            "overall": "ç·åˆè©•ä¾¡ï¼ˆå…¨ä½“ã®å°è±¡ã¨æ¬¡å›ã¸ã®å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€‚100-200æ–‡å­—ç¨‹åº¦ï¼‰",
            "analysis": {{
                "questions_count": æ•°å€¤,
                "listening_responses_count": æ•°å€¤,
                "proposals_count": æ•°å€¤,
                "closings_count": æ•°å€¤,
                "conversation_flow": "ä¼šè©±ã®æµã‚Œã®åˆ†æï¼ˆæŒ¨æ‹¶â†’ãƒ’ã‚¢ãƒªãƒ³ã‚°â†’ææ¡ˆâ†’ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã®ã©ã®æ®µéšã¾ã§é€²ã‚“ã ã‹ï¼‰"
            }}
        }}

        ã€æ³¨æ„ã€‘
        - strengthsï¼ˆè‰¯ã‹ã£ãŸç‚¹ï¼‰ã«ã¯æœ€ä½3é …ç›®ã€æœ€å¤§5é …ç›®ã‚’è¨˜è¼‰
        - improvementsï¼ˆæ”¹å–„ç‚¹ï¼‰ã«ã¯æœ€ä½3é …ç›®ã€æœ€å¤§5é …ç›®ã‚’è¨˜è¼‰
        - å„é …ç›®ã¯å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ã€ã€Œãªãœè‰¯ã„/æ‚ªã„ã€ã€Œã©ã†æ”¹å–„ã™ã¹ãã€ã‚’æ˜è¨˜
        - è©•ä¾¡ã¯å®Ÿè·µçš„ã§ã€æ¬¡å›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ã§å³å®Ÿè¡Œã§ãã‚‹å†…å®¹ã«ã™ã‚‹
        """
        
        response = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": """ã‚ãªãŸã¯ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»åˆ¶ä½œå–¶æ¥­ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ¼ãƒã§ã™ã€‚
10å¹´ä»¥ä¸Šã®å–¶æ¥­çµŒé¨“ã‚’æŒã¡ã€1000ä»¶ä»¥ä¸Šã®ãƒ­ãƒ¼ãƒ—ãƒ¬ã‚’è©•ä¾¡ã—ã¦ãã¾ã—ãŸã€‚
å–¶æ¥­ã®ç™ºè¨€ã‚’è©³ç´°ã«åˆ†æã—ã€å…·ä½“çš„ãªç™ºè¨€ã‚’å¼•ç”¨ã—ãªãŒã‚‰ã€å®Ÿè·µçš„ã§çš„ç¢ºãªè©•ä¾¡ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
è‰¯ã‹ã£ãŸç‚¹ã¨æ”¹å–„ç‚¹ã‚’æ˜ç¢ºã«åˆ†ã‘ã€æ¬¡å›ã®ãƒ­ãƒ¼ãƒ—ãƒ¬ã§å³å®Ÿè¡Œã§ãã‚‹å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"""},
                {"role": "user", "content": evaluation_prompt}
            ],
            max_tokens=1500,  # ã‚ˆã‚Šè©³ç´°ãªè©•ä¾¡ã®ãŸã‚å¢—é‡
            temperature=0.3
        )
        
        # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
        evaluation_text = response.choices[0].message.content.strip()
        
        # JSONã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¤œç´¢
        start_idx = evaluation_text.find('{')
        end_idx = evaluation_text.rfind('}') + 1
        
        if start_idx != -1 and end_idx != -1:
            json_text = evaluation_text[start_idx:end_idx]
            evaluation = json.loads(json_text)

            # åŸºæœ¬æƒ…å ±ã‚’è¿½åŠ 
            evaluation['total_utterances'] = len(sales_utterances)

            # overallãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ­£è¦åŒ–ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›æ€§ã®ãŸã‚ï¼‰
            if 'overall' not in evaluation or not evaluation['overall']:
                if 'overall_comment' in evaluation:
                    evaluation['overall'] = evaluation['overall_comment']
                else:
                    evaluation['overall'] = "è©•ä¾¡ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚"

            # strengths/improvementsãŒå­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯ç©ºã®å ´åˆ
            if 'strengths' not in evaluation or not evaluation['strengths']:
                evaluation['strengths'] = ["è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­ã§ã™ã€‚"]

            if 'improvements' not in evaluation or not evaluation['improvements']:
                evaluation['improvements'] = ["ç¶™ç¶šçš„ãªç·´ç¿’ã§æ›´ãªã‚‹å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã—ã‚‡ã†ã€‚"]

            return evaluation
        else:
            # JSONè§£æã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return generate_evaluation_fallback(sales_utterances)
            
    except Exception as e:
        print(f"GPT-4è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
        return generate_evaluation_fallback(sales_utterances)

def generate_evaluation_fallback(sales_utterances):
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®è©•ä¾¡ç”Ÿæˆï¼ˆå¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
    
    # åŸºæœ¬çš„ãªè©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
    total_utterances = len(sales_utterances)
    
    # è³ªå•åŠ›ã®è©•ä¾¡ï¼ˆã‚ˆã‚Šè©³ç´°ãªåˆ†æï¼‰
    question_words = ['ä½•', 'ã©ã®', 'ãªãœ', 'ã©ã†ã—ã¦', 'ã„ã¤', 'ã©ã“', 'èª°', 'ã„ãã¤', 'ã„ãã‚‰', 'ã©ã®ã‚ˆã†ã«', 'ãªãœ', 'ã©ã†ã‚„ã£ã¦']
    open_questions = ['ã©ã®ã‚ˆã†ã«', 'ãªãœ', 'ã©ã†ã—ã¦', 'ã©ã®ã‚ˆã†ãª']
    questions = [utterance for utterance in sales_utterances 
                if any(word in utterance for word in question_words)]
    open_questions_count = len([utterance for utterance in sales_utterances 
                               if any(word in utterance for word in open_questions)])
    
    questioning_score = min(5, (len(questions) * 1.5) + (open_questions_count * 0.5))
    
    # å‚¾è´åŠ›ã®è©•ä¾¡ï¼ˆã‚ˆã‚Šå¤šæ§˜ãªè¡¨ç¾ã‚’æ¤œå‡ºï¼‰
    listening_words = ['ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ç¢ºã‹ã«', 'ãŠã£ã—ã‚ƒã‚‹é€šã‚Š', 'ç†è§£ã—ã¾ã—ãŸ', 'æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸ', 
                      'ãŠèã‹ã›ãã ã•ã„', 'è©³ã—ãæ•™ãˆã¦ãã ã•ã„', 'èˆˆå‘³æ·±ã„ã§ã™ã­', 'ãã‚Œã¯å¤§å¤‰ã§ã™ã­']
    listening_responses = [utterance for utterance in sales_utterances 
                          if any(word in utterance for word in listening_words)]
    listening_score = min(5, len(listening_responses) * 1.5)
    
    # ææ¡ˆåŠ›ã®è©•ä¾¡ï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªææ¡ˆè¡¨ç¾ï¼‰
    proposal_words = ['ææ¡ˆ', 'ãŠã™ã™ã‚', 'è§£æ±º', 'æ”¹å–„', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'æ¡ˆ', 'æ–¹æ³•', 'ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³', 
                     'ãŠæ‰‹ä¼ã„', 'ã‚µãƒãƒ¼ãƒˆ', 'ã”æä¾›', 'ã”æ¡ˆå†…']
    proposals = [utterance for utterance in sales_utterances 
                if any(word in utterance for word in proposal_words)]
    proposing_score = min(5, len(proposals) * 1.5)
    
    # ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°åŠ›ã®è©•ä¾¡ï¼ˆã‚ˆã‚Šå¤šæ§˜ãªã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°è¡¨ç¾ï¼‰
    closing_words = ['ã„ã‹ãŒã§ã—ã‚‡ã†ã‹', 'æ¤œè¨', 'ãŠæ™‚é–“', 'ã”é€£çµ¡', 'æ¬¡å›', 'å¾Œæ—¥', 'ã”æ¤œè¨', 'ãŠè€ƒãˆ', 
                    'ãŠæ±ºã‚', 'ãŠè¿”äº‹', 'ã”è¿”ç­”', 'ãŠå¾…ã¡', 'ãŠèã‹ã›']
    closings = [utterance for utterance in sales_utterances 
               if any(word in utterance for word in closing_words)]
    closing_score = min(5, len(closings) * 1.5)
    
    # æ„Ÿæƒ…åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
    positive_words = ['ã‚ã‚ŠãŒã¨ã†', 'æ„Ÿè¬', 'å¬‰ã—ã„', 'ç´ æ™´ã‚‰ã—ã„', 'è‰¯ã„', 'åŠ©ã‹ã‚Šã¾ã™', 'å¿ƒå¼·ã„']
    negative_words = ['å›°ã£ã¦', 'å¤§å¤‰', 'é›£ã—ã„', 'å•é¡Œ', 'èª²é¡Œ', 'æ‚©ã¿']
    
    positive_count = len([utterance for utterance in sales_utterances 
                         if any(word in utterance for word in positive_words)])
    negative_count = len([utterance for utterance in sales_utterances 
                         if any(word in utterance for word in negative_words)])
    
    # ä¼šè©±ã®æµã‚Œåˆ†æ
    conversation_flow = analyze_conversation_flow(sales_utterances)
    
    # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿ä»˜ã‘ï¼‰
    total_score = (questioning_score * 0.25 + listening_score * 0.25 + 
                  proposing_score * 0.3 + closing_score * 0.2)
    
    # é«˜åº¦ãªè©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
    comments = generate_advanced_comments(questioning_score, listening_score, proposing_score, 
                                        closing_score, conversation_flow, positive_count, negative_count)
    
    # ç·åˆè©•ä¾¡ï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰
    overall_comment = generate_overall_comment(total_score, conversation_flow, positive_count, negative_count)
    
    # æ”¹å–„ææ¡ˆ
    improvement_suggestions = generate_improvement_suggestions(questioning_score, listening_score, 
                                                             proposing_score, closing_score, conversation_flow)
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›æ€§ã®ãŸã‚ã€strengths ã¨ improvements ã‚’è¿½åŠ 
    strengths = []
    improvements = []

    # commentsã‹ã‚‰è‰¯ã‹ã£ãŸç‚¹ã‚’æŠ½å‡º
    if comments:
        for comment in comments:
            if 'âœ…' in comment or 'ğŸ‘' in comment or 'â­' in comment or 'è‰¯ã„' in comment or 'å„ªç§€' in comment:
                strengths.append(comment)
            else:
                improvements.append(comment)

    # improvement_suggestionsã‚’improvementsã«è¿½åŠ 
    if improvement_suggestions:
        improvements.extend(improvement_suggestions)

    # æœ€ä½é™ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¿è¨¼
    if not strengths:
        strengths = [overall_comment if overall_comment else "è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚"]

    if not improvements:
        improvements = ["ã•ã‚‰ãªã‚‹å‘ä¸Šã®ãŸã‚ã€ç¶™ç¶šçš„ãªç·´ç¿’ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ã€‚"]

    return {
        'scores': {
            'questioning': round(questioning_score, 1),
            'listening': round(listening_score, 1),
            'proposing': round(proposing_score, 1),
            'closing': round(closing_score, 1),
            'total': round(total_score, 1)
        },
        'overall': overall_comment,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
        'strengths': strengths,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
        'improvements': improvements,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å
        'comments': comments,
        'overall_comment': overall_comment,  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒ
        'improvement_suggestions': improvement_suggestions,  # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒ
        'total_utterances': total_utterances,
        'analysis': {
            'questions_count': len(questions),
            'open_questions_count': open_questions_count,
            'listening_responses_count': len(listening_responses),
            'proposals_count': len(proposals),
            'closings_count': len(closings),
            'positive_expressions': positive_count,
            'negative_expressions': negative_count,
            'conversation_flow': conversation_flow
        }
    }

def analyze_conversation_flow(utterances):
    """ä¼šè©±ã®æµã‚Œã‚’åˆ†æ"""
    if len(utterances) < 2:
        return "çŸ­ã„ä¼šè©±"
    
    # ä¼šè©±ã®æ®µéšã‚’åˆ†æ
    stages = {
        'greeting': 0,  # æŒ¨æ‹¶
        'needs_analysis': 0,  # ãƒ‹ãƒ¼ã‚ºåˆ†æ
        'proposal': 0,  # ææ¡ˆ
        'objection_handling': 0,  # åå¯¾æ„è¦‹å¯¾å¿œ
        'closing': 0  # ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°
    }
    
    for utterance in utterances:
        if any(word in utterance for word in ['ã“ã‚“ã«ã¡ã¯', 'ã¯ã˜ã‚ã¾ã—ã¦', 'ãŠå¿™ã—ã„ä¸­']):
            stages['greeting'] += 1
        elif any(word in utterance for word in ['å›°ã£ã¦', 'èª²é¡Œ', 'å•é¡Œ', 'æ‚©ã¿', 'ã©ã®ã‚ˆã†ãª']):
            stages['needs_analysis'] += 1
        elif any(word in utterance for word in ['ææ¡ˆ', 'ãŠã™ã™ã‚', 'è§£æ±º', 'ã‚µãƒ¼ãƒ“ã‚¹']):
            stages['proposal'] += 1
        elif any(word in utterance for word in ['ã§ã‚‚', 'ã—ã‹ã—', 'å¿ƒé…', 'ä¸å®‰']):
            stages['objection_handling'] += 1
        elif any(word in utterance for word in ['ã„ã‹ãŒã§ã—ã‚‡ã†ã‹', 'æ¤œè¨', 'ãŠæ™‚é–“']):
            stages['closing'] += 1
    
    # æœ€ã‚‚å¤šã„æ®µéšã‚’ç‰¹å®š
    max_stage = max(stages, key=stages.get)
    return max_stage

def generate_advanced_comments(questioning, listening, proposing, closing, flow, positive, negative):
    """é«˜åº¦ãªè©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    comments = []
    
    # è³ªå•åŠ›ã®è©³ç´°è©•ä¾¡
    if questioning >= 4:
        comments.append("âœ… ç›¸æ‰‹ã®èª²é¡Œã‚’ç©æ¥µçš„ã«å¼•ãå‡ºã›ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚‚åŠ¹æœçš„ã«ä½¿ç”¨ã—ã¦ã„ã¾ã™")
    elif questioning >= 2:
        comments.append("âš ï¸ è³ªå•ã¯ã§ãã¦ã„ã¾ã™ãŒã€ã‚ˆã‚Šæ·±æ˜ã‚Šã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†")
    else:
        comments.append("âŒ è³ªå•ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç›¸æ‰‹ã®ãƒ‹ãƒ¼ã‚ºã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ç©æ¥µçš„ã«è³ªå•ã—ã¾ã—ã‚‡ã†")
    
    # å‚¾è´åŠ›ã®è©³ç´°è©•ä¾¡
    if listening >= 4:
        comments.append("âœ… ç›¸æ‰‹ã®è©±ã‚’ã‚ˆãèãã€å…±æ„Ÿã‚’ç¤ºã™è¡¨ç¾ãŒè±Šå¯Œã§ã™")
    elif listening >= 2:
        comments.append("âš ï¸ åŸºæœ¬çš„ãªå‚¾è´ã¯ã§ãã¦ã„ã¾ã™ãŒã€ã‚ˆã‚Šå¤šæ§˜ãªå…±æ„Ÿè¡¨ç¾ã‚’ä½¿ã„ã¾ã—ã‚‡ã†")
    else:
        comments.append("âŒ å‚¾è´åŠ›ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç›¸æ‰‹ã®è©±ã«å…±æ„Ÿã™ã‚‹è¡¨ç¾ã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†")
    
    # ææ¡ˆåŠ›ã®è©³ç´°è©•ä¾¡
    if proposing >= 4:
        comments.append("âœ… å…·ä½“çš„ã§é­…åŠ›çš„ãªææ¡ˆãŒã§ãã¦ã„ã¾ã™")
    elif proposing >= 2:
        comments.append("âš ï¸ ææ¡ˆã¯ã—ã¦ã„ã¾ã™ãŒã€ã‚ˆã‚Šå…·ä½“çš„ãªãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã‚’ä¼ãˆã¾ã—ã‚‡ã†")
    else:
        comments.append("âŒ ææ¡ˆåŠ›ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç›¸æ‰‹ã®èª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã‚’æ˜ç¢ºã«æç¤ºã—ã¾ã—ã‚‡ã†")
    
    # ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°åŠ›ã®è©³ç´°è©•ä¾¡
    if closing >= 4:
        comments.append("âœ… æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ä¿ƒã›ã¦ãŠã‚Šã€ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ãŒä¸Šæ‰‹ã§ã™")
    elif closing >= 2:
        comments.append("âš ï¸ ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã¯ã—ã¦ã„ã¾ã™ãŒã€ã‚ˆã‚Šå…·ä½“çš„ãªæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã—ã¾ã—ã‚‡ã†")
    else:
        comments.append("âŒ ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ä¼šè©±ã®çµ‚ã‚ã‚Šã«æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ã—ã¾ã—ã‚‡ã†")
    
    # ä¼šè©±ã®æµã‚Œã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ
    if flow == 'greeting':
        comments.append("ğŸ’¡ æŒ¨æ‹¶æ®µéšã§æ­¢ã¾ã£ã¦ã„ã¾ã™ã€‚ãƒ‹ãƒ¼ã‚ºåˆ†æã«é€²ã¿ã¾ã—ã‚‡ã†")
    elif flow == 'needs_analysis':
        comments.append("ğŸ’¡ ãƒ‹ãƒ¼ã‚ºåˆ†æã¯ã§ãã¦ã„ã¾ã™ã€‚ææ¡ˆæ®µéšã«é€²ã¿ã¾ã—ã‚‡ã†")
    elif flow == 'proposal':
        comments.append("ğŸ’¡ ææ¡ˆã¯ã§ãã¦ã„ã¾ã™ã€‚ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã«é€²ã¿ã¾ã—ã‚‡ã†")
    elif flow == 'closing':
        comments.append("ğŸ’¡ è‰¯ã„ä¼šè©±ã®æµã‚Œã§ã™ã€‚ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã¾ã§åˆ°é”ã§ãã¦ã„ã¾ã™")
    
    # æ„Ÿæƒ…åˆ†æã«é–¢ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ
    if positive > negative:
        comments.append("ğŸ˜Š ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ãŒå¤šãã€è‰¯ã„é–¢ä¿‚æ€§ã‚’ç¯‰ã‘ã¦ã„ã¾ã™")
    elif negative > positive:
        comments.append("ğŸ˜Ÿ ãƒã‚¬ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ãŒå¤šã„ã§ã™ã€‚ã‚ˆã‚Šãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†")
    
    return comments

def generate_overall_comment(total_score, flow, positive, negative):
    """ç·åˆè©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆ"""
    if total_score >= 4.5:
        return "ğŸŒŸ ç´ æ™´ã‚‰ã—ã„å–¶æ¥­ã‚¹ã‚­ãƒ«ã§ã™ï¼ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«ã®å¯¾å¿œãŒã§ãã¦ã„ã¾ã™ã€‚"
    elif total_score >= 4:
        return "â­ å„ªç§€ãªå–¶æ¥­ã‚¹ã‚­ãƒ«ã§ã™ã€‚ã•ã‚‰ã«ç£¨ãã‚’ã‹ã‘ã¦å®Œç’§ã‚’ç›®æŒ‡ã—ã¾ã—ã‚‡ã†ã€‚"
    elif total_score >= 3:
        return "ğŸ‘ è‰¯ã„å–¶æ¥­ã‚¹ã‚­ãƒ«ã§ã™ã€‚ç¶™ç¶šçš„ãªç·´ç¿’ã§ã•ã‚‰ã«å‘ä¸Šã•ã›ã¾ã—ã‚‡ã†ã€‚"
    elif total_score >= 2:
        return "ğŸ“ˆ åŸºæœ¬çš„ãªå–¶æ¥­ã‚¹ã‚­ãƒ«ã¯ã‚ã‚Šã¾ã™ã€‚å¼±ç‚¹ã‚’å…‹æœã—ã¦ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ã—ã¾ã—ã‚‡ã†ã€‚"
    else:
        return "ğŸ¯ å–¶æ¥­ã‚¹ã‚­ãƒ«ã®åŸºç¤ã‚’å›ºã‚ã¾ã—ã‚‡ã†ã€‚ä¸€ã¤ãšã¤ç¢ºå®Ÿã«èº«ã«ã¤ã‘ã¦ã„ãã¾ã—ã‚‡ã†ã€‚"

def generate_improvement_suggestions(questioning, listening, proposing, closing, flow):
    """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
    suggestions = []
    
    if questioning < 3:
        suggestions.append("ğŸ“ è³ªå•åŠ›å‘ä¸Š: 5W1Hï¼ˆä½•ãƒ»èª°ãƒ»ã„ã¤ãƒ»ã©ã“ãƒ»ãªãœãƒ»ã©ã®ã‚ˆã†ã«ï¼‰ã‚’æ„è­˜ã—ãŸè³ªå•ã‚’ç·´ç¿’ã—ã¾ã—ã‚‡ã†")
    
    if listening < 3:
        suggestions.append("ğŸ‘‚ å‚¾è´åŠ›å‘ä¸Š: ç›¸æ‰‹ã®è©±ã‚’èãéš›ã¯ã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã§ã™ã­ã€ãªã©ã®ç›¸ã¥ã¡ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†")
    
    if proposing < 3:
        suggestions.append("ğŸ’¡ ææ¡ˆåŠ›å‘ä¸Š: ç›¸æ‰‹ã®èª²é¡Œã«å¯¾ã™ã‚‹å…·ä½“çš„ãªè§£æ±ºç­–ã¨ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã‚’æ˜ç¢ºã«ä¼ãˆã¾ã—ã‚‡ã†")
    
    if closing < 3:
        suggestions.append("ğŸ¯ ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°åŠ›å‘ä¸Š: ä¼šè©±ã®çµ‚ã‚ã‚Šã«ã¯å¿…ãšæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ˜ç¢ºã«ææ¡ˆã—ã¾ã—ã‚‡ã†")
    
    if flow == 'greeting':
        suggestions.append("ğŸ”„ ä¼šè©±ã®æµã‚Œ: æŒ¨æ‹¶ã®å¾Œã¯ç›¸æ‰‹ã®èª²é¡Œã‚„ãƒ‹ãƒ¼ã‚ºã‚’èãè³ªå•ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†")
    
    return suggestions

# ===== Week 3: ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–æ©Ÿèƒ½ =====

@app.route('/api/conversations', methods=['POST'])
def save_conversation():
    """ä¼šè©±å±¥æ­´ã‚’Supabaseã«ä¿å­˜"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

        data = request.get_json()
        user_id = data.get('user_id')
        store_id = data.get('store_id')
        scenario_id = data.get('scenario_id')
        messages = data.get('messages', [])
        duration = data.get('duration_seconds', 0)

        if not user_id or not scenario_id:
            return jsonify({'success': False, 'error': 'user_idã¨scenario_idã¯å¿…é ˆã§ã™'}), 400

        # conversationsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        result = supabase_client.table('conversations').insert({
            'user_id': user_id,
            'store_id': store_id,
            'scenario_id': scenario_id,
            'scenario_title': data.get('scenario_title', scenario_id),
            'messages': messages,
            'duration_seconds': duration
        }).execute()

        return jsonify({
            'success': True,
            'conversation_id': result.data[0]['id'] if result.data else None,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/conversations', methods=['GET'])
def get_conversations():
    """ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

        user_id = request.args.get('user_id')
        scenario_id = request.args.get('scenario_id')
        limit = request.args.get('limit', 50)

        if not user_id:
            return jsonify({'success': False, 'error': 'user_idã¯å¿…é ˆã§ã™'}), 400

        # conversationsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
        query = supabase_client.table('conversations').select('*').eq('user_id', user_id)

        if scenario_id:
            query = query.eq('scenario_id', scenario_id)

        result = query.order('created_at', desc=True).limit(limit).execute()

        return jsonify({
            'success': True,
            'conversations': result.data,
            'count': len(result.data)
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/evaluations', methods=['GET', 'POST'])
def handle_evaluations():
    """è©•ä¾¡å±¥æ­´ã®å–å¾—ã¾ãŸã¯ä¿å­˜"""
    if request.method == 'GET':
        # è©•ä¾¡å±¥æ­´ã‚’å–å¾—
        try:
            if not supabase_client:
                return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

            user_id = request.args.get('user_id')
            scenario_id = request.args.get('scenario_id')
            limit = request.args.get('limit', 50)

            if not user_id:
                return jsonify({'success': False, 'error': 'user_idã¯å¿…é ˆã§ã™'}), 400

            # evaluationsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—
            query = supabase_client.table('evaluations').select('*').eq('user_id', user_id)

            if scenario_id:
                query = query.eq('scenario_id', scenario_id)

            result = query.order('created_at', desc=True).limit(limit).execute()

            return jsonify({
                'success': True,
                'evaluations': result.data,
                'count': len(result.data)
            })

        except Exception as e:
            import traceback
            traceback.print_exc()
            return jsonify({'success': False, 'error': str(e)}), 500

    else:  # POST
        # è©•ä¾¡å±¥æ­´ã‚’ä¿å­˜
        try:
            if not supabase_client:
                return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

            data = request.get_json()
            conversation_id = data.get('conversation_id')
            user_id = data.get('user_id')
            store_id = data.get('store_id')
            scenario_id = data.get('scenario_id')
            scores = data.get('scores', {})
            comments = data.get('comments', {})

            if not user_id or not scenario_id:
                return jsonify({'success': False, 'error': 'user_idã¨scenario_idã¯å¿…é ˆã§ã™'}), 400

            # ã‚¹ã‚³ã‚¢ã®åˆè¨ˆã¨å¹³å‡ã‚’è¨ˆç®—ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰æ¥ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’è€ƒæ…®ï¼‰
            total_score = sum([
                scores.get('questioning_skill', scores.get('questioning', 0)),
                scores.get('listening_skill', scores.get('listening', 0)),
                scores.get('proposal_skill', scores.get('proposing', 0)),
                scores.get('closing_skill', scores.get('closing', 0))
            ])
            average_score = total_score / 4

            # evaluationsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            result = supabase_client.table('evaluations').insert({
                'conversation_id': conversation_id,
                'user_id': user_id,
                'store_id': store_id,
                'scenario_id': scenario_id,
                'scores': scores,
                'total_score': int(total_score),
                'average_score': round(average_score, 2),
                'comments': comments
            }).execute()

            return jsonify({
                'success': True,
                'evaluation_id': result.data[0]['id'] if result.data else None,
                'timestamp': datetime.now().isoformat()
            })

        except Exception as e:
            import traceback
            traceback.print_exc()
            return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/ingest', methods=['GET', 'POST'])
def ingest_videos():
    """å‹•ç”»å–ã‚Šè¾¼ã¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ"""
    try:
        import subprocess
        script_path = os.path.join(os.path.dirname(__file__), 'tools', 'batch_ingest_videos.py')
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'å–ã‚Šè¾¼ã¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 404
        
        # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ
        result = subprocess.run(
            [sys.executable, script_path],
            cwd=os.path.dirname(__file__),
            capture_output=True,
            text=True,
            encoding='utf-8'
        )
        
        # ã‚·ãƒŠãƒªã‚ªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†èª­ã¿è¾¼ã¿
        load_scenarios_index()
        
        # çµæœã‚’å–å¾—
        output = result.stdout
        error = result.stderr
        
        # ä½œæˆä»¶æ•°ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        scenarios_created = 0
        rag_items = 0
        
        if 'ä½œæˆã‚·ãƒŠãƒªã‚ªæ•°:' in output:
            match = re.search(r'ä½œæˆã‚·ãƒŠãƒªã‚ªæ•°:\s*(\d+)', output)
            if match:
                scenarios_created = int(match.group(1))
        
        if 'RAGã‚¢ã‚¤ãƒ†ãƒ æ•°:' in output:
            match = re.search(r'RAGã‚¢ã‚¤ãƒ†ãƒ æ•°:\s*(\d+)', output)
            if match:
                rag_items = int(match.group(1))
        
        return jsonify({
            'success': True,
            'scenarios_created': scenarios_created,
            'rag_items': rag_items,
            'output': output,
            'error': error
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/admin/stores/stats', methods=['GET'])
def get_stores_stats():
    """å…¨åº—èˆ—ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆæœ¬éƒ¨ç®¡ç†è€…å°‚ç”¨ï¼‰"""
    try:
        # Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # å…¨åº—èˆ—å–å¾—
        stores_result = supabase_client.table('stores').select('*').execute()
        stores = stores_result.data if stores_result.data else []

        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
        profiles_result = supabase_client.table('profiles').select('id, store_id').execute()
        total_users = len(profiles_result.data) if profiles_result.data else 0

        # å…¨ä¼šè©±æ•°
        conversations_result = supabase_client.table('conversations').select('id').execute()
        total_conversations = len(conversations_result.data) if conversations_result.data else 0

        # å…¨è©•ä¾¡æ•°ã¨å¹³å‡ã‚¹ã‚³ã‚¢
        evaluations_result = supabase_client.table('evaluations').select('average_score').execute()
        evaluations = evaluations_result.data if evaluations_result.data else []
        total_evaluations = len(evaluations)
        overall_avg_score = sum(e['average_score'] for e in evaluations) / total_evaluations if total_evaluations > 0 else 0

        return jsonify({
            'success': True,
            'stats': {
                'total_stores': len(stores),
                'total_users': total_users,
                'total_conversations': total_conversations,
                'total_evaluations': total_evaluations,
                'overall_avg_score': round(overall_avg_score, 2)
            }
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/admin/stores/rankings', methods=['GET'])
def get_stores_rankings():
    """åº—èˆ—åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ï¼ˆæœ¬éƒ¨ç®¡ç†è€…å°‚ç”¨ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # å…¨åº—èˆ—å–å¾—
        stores_result = supabase_client.table('stores').select('*').execute()
        stores = stores_result.data if stores_result.data else []

        rankings = []
        for store in stores:
            store_id = store['id']

            # åº—èˆ—ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
            profiles_result = supabase_client.table('profiles').select('id').eq('store_id', store_id).execute()
            user_count = len(profiles_result.data) if profiles_result.data else 0

            # åº—èˆ—ã®ä¼šè©±æ•°
            conversations_result = supabase_client.table('conversations').select('id').eq('store_id', store_id).execute()
            conversation_count = len(conversations_result.data) if conversations_result.data else 0

            # åº—èˆ—ã®è©•ä¾¡å¹³å‡ã‚¹ã‚³ã‚¢
            evaluations_result = supabase_client.table('evaluations').select('average_score').eq('store_id', store_id).execute()
            evaluations = evaluations_result.data if evaluations_result.data else []
            avg_score = sum(e['average_score'] for e in evaluations) / len(evaluations) if evaluations else 0

            rankings.append({
                'store_id': store_id,
                'store_code': store['store_code'],
                'store_name': store['store_name'],
                'region': store.get('region'),
                'user_count': user_count,
                'conversation_count': conversation_count,
                'evaluation_count': len(evaluations),
                'average_score': round(avg_score, 2)
            })

        # å¹³å‡ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        rankings.sort(key=lambda x: x['average_score'], reverse=True)

        return jsonify({
            'success': True,
            'rankings': rankings
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/stores/<store_id>/members', methods=['GET'])
def get_store_members(store_id):
    """åº—èˆ—ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§ã‚’å–å¾—ï¼ˆåº—èˆ—ç®¡ç†è€…ãƒ»æœ¬éƒ¨ç®¡ç†è€…ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # ãƒ¡ãƒ³ãƒãƒ¼å–å¾—
        profiles_result = supabase_client.table('profiles').select('*').eq('store_id', store_id).execute()
        members = profiles_result.data if profiles_result.data else []

        # å„ãƒ¡ãƒ³ãƒãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        for member in members:
            user_id = member['id']

            # ä¼šè©±æ•°
            conversations_result = supabase_client.table('conversations').select('id').eq('user_id', user_id).execute()
            member['conversation_count'] = len(conversations_result.data) if conversations_result.data else 0

            # è©•ä¾¡å¹³å‡ã‚¹ã‚³ã‚¢
            evaluations_result = supabase_client.table('evaluations').select('average_score').eq('user_id', user_id).execute()
            evaluations = evaluations_result.data if evaluations_result.data else []
            member['average_score'] = round(sum(e['average_score'] for e in evaluations) / len(evaluations), 2) if evaluations else 0
            member['evaluation_count'] = len(evaluations)

        return jsonify({
            'success': True,
            'members': members
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/admin/regions/stats', methods=['GET'])
def get_regions_stats():
    """ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥é›†è¨ˆã‚’å–å¾—ï¼ˆæœ¬éƒ¨ç®¡ç†è€…å°‚ç”¨ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # å…¨åº—èˆ—å–å¾—
        stores_result = supabase_client.table('stores').select('*').execute()
        stores = stores_result.data if stores_result.data else []

        # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        regions = {}
        for store in stores:
            region = store.get('region', 'æœªè¨­å®š')
            if region not in regions:
                regions[region] = {
                    'region': region,
                    'store_count': 0,
                    'total_users': 0,
                    'total_conversations': 0,
                    'total_evaluations': 0,
                    'total_score': 0,
                    'stores': []
                }

            store_id = store['id']

            # åº—èˆ—ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
            profiles_result = supabase_client.table('profiles').select('id').eq('store_id', store_id).execute()
            user_count = len(profiles_result.data) if profiles_result.data else 0

            # åº—èˆ—ã®ä¼šè©±æ•°
            conversations_result = supabase_client.table('conversations').select('id').eq('store_id', store_id).execute()
            conversation_count = len(conversations_result.data) if conversations_result.data else 0

            # åº—èˆ—ã®è©•ä¾¡å¹³å‡ã‚¹ã‚³ã‚¢
            evaluations_result = supabase_client.table('evaluations').select('average_score').eq('store_id', store_id).execute()
            evaluations = evaluations_result.data if evaluations_result.data else []
            avg_score = sum(e['average_score'] for e in evaluations) / len(evaluations) if evaluations else 0

            # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®çµ±è¨ˆã‚’æ›´æ–°
            regions[region]['store_count'] += 1
            regions[region]['total_users'] += user_count
            regions[region]['total_conversations'] += conversation_count
            regions[region]['total_evaluations'] += len(evaluations)
            if evaluations:
                regions[region]['total_score'] += avg_score

            # åº—èˆ—æƒ…å ±ã‚’è¿½åŠ 
            regions[region]['stores'].append({
                'store_id': store_id,
                'store_code': store['store_code'],
                'store_name': store['store_name'],
                'user_count': user_count,
                'conversation_count': conversation_count,
                'evaluation_count': len(evaluations),
                'average_score': round(avg_score, 2)
            })

        # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        region_stats = []
        for region_name, region_data in regions.items():
            store_count = region_data['store_count']
            avg_score = region_data['total_score'] / store_count if store_count > 0 else 0

            region_stats.append({
                'region': region_name,
                'store_count': store_count,
                'total_users': region_data['total_users'],
                'total_conversations': region_data['total_conversations'],
                'total_evaluations': region_data['total_evaluations'],
                'average_score': round(avg_score, 2),
                'stores': region_data['stores']
            })

        # å¹³å‡ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        region_stats.sort(key=lambda x: x['average_score'], reverse=True)

        return jsonify({
            'success': True,
            'regions': region_stats
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/stores/<store_id>/analytics', methods=['GET'])
def get_store_analytics(store_id):
    """åº—èˆ—åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆåº—èˆ—ç®¡ç†è€…ãƒ»æœ¬éƒ¨ç®¡ç†è€…ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # åº—èˆ—æƒ…å ±
        store_result = supabase_client.table('stores').select('*').eq('id', store_id).execute()
        if not store_result.data:
            return jsonify({'success': False, 'error': 'Store not found'}), 404

        store = store_result.data[0]

        # ã‚·ãƒŠãƒªã‚ªåˆ¥çµ±è¨ˆ
        evaluations_result = supabase_client.table('evaluations').select('scenario_id, average_score').eq('store_id', store_id).execute()
        evaluations = evaluations_result.data if evaluations_result.data else []

        scenario_stats = {}
        for eval in evaluations:
            scenario_id = eval['scenario_id']
            if scenario_id not in scenario_stats:
                scenario_stats[scenario_id] = {'count': 0, 'total_score': 0}
            scenario_stats[scenario_id]['count'] += 1
            scenario_stats[scenario_id]['total_score'] += eval['average_score']

        scenario_analytics = []
        for scenario_id, stats in scenario_stats.items():
            scenario_analytics.append({
                'scenario_id': scenario_id,
                'count': stats['count'],
                'average_score': round(stats['total_score'] / stats['count'], 2)
            })

        return jsonify({
            'success': True,
            'store': store,
            'scenario_analytics': scenario_analytics,
            'total_evaluations': len(evaluations)
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# é™çš„ã‚¢ã‚»ãƒƒãƒˆã‚’é…ä¿¡
@app.route('/assets/<path:filename>')
def serve_assets(filename):
    """Viteã§ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸã‚¢ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ä¿¡"""
    from flask import send_from_directory
    assets_path = os.path.join(os.path.dirname(__file__), 'dist', 'assets')
    return send_from_directory(assets_path, filename)


# ã‚­ãƒ£ãƒƒãƒã‚ªãƒ¼ãƒ«ãƒ«ãƒ¼ãƒˆ: React Routerã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
@app.route('/<path:path>')
def catch_all(path):
    """
    APIãƒ«ãƒ¼ãƒˆä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ‘ã‚¹ã§index.htmlã‚’è¿”ã™
    ã“ã‚Œã«ã‚ˆã‚ŠReact RouterãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å‡¦ç†ã§ãã‚‹
    """
    from flask import send_from_directory
    print(f"ğŸ” Catch-all route called with path: {path}")

    # APIãƒ«ãƒ¼ãƒˆã¯é™¤å¤–
    if path.startswith('api/'):
        print(f"âŒ API route, returning 404: {path}")
        return jsonify({'error': 'Not found'}), 404

    # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‹•ç”»ãƒ»ç”»åƒï¼‰ã‚’é…ä¿¡
    if path.endswith(('.mp4', '.webm', '.jpg', '.jpeg', '.png', '.gif', '.svg', '.ico')):
        dist_path = os.path.join(os.path.dirname(__file__), 'dist')
        file_path = os.path.join(dist_path, path)
        if os.path.exists(file_path):
            print(f"ğŸ“¹ Serving media file: {path}")
            return send_from_directory(dist_path, path)

    # distãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®index.htmlã‚’è¿”ã™
    dist_index = os.path.join(os.path.dirname(__file__), 'dist', 'index.html')
    print(f"ğŸ“ Looking for index.html at: {dist_index}")
    print(f"âœ… File exists: {os.path.exists(dist_index)}")

    if os.path.exists(dist_index):
        print(f"âœ… Serving index.html for path: {path}")
        with open(dist_index, 'r', encoding='utf-8') as f:
            return f.read()

    print(f"âŒ index.html not found at: {dist_index}")
    return jsonify({'error': 'Frontend not built', 'path': path}), 404


# ===== Week 6: CSVä¸€æ‹¬å‡ºåŠ›æ©Ÿèƒ½ =====

@app.route('/api/admin/export/evaluations', methods=['GET'])
def export_all_evaluations():
    """å…¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§å‡ºåŠ›ï¼ˆæœ¬éƒ¨ç®¡ç†è€…å°‚ç”¨ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        store_id = request.args.get('store_id')
        region = request.args.get('region')
        scenario_id = request.args.get('scenario_id')

        # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
        query = supabase_client.table('evaluations').select('*')

        if store_id:
            query = query.eq('store_id', store_id)

        if scenario_id:
            query = query.eq('scenario_id', scenario_id)

        query = query.order('created_at', desc=True)
        evaluations_result = query.execute()
        evaluations = evaluations_result.data if evaluations_result.data else []

        # åº—èˆ—æƒ…å ±ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
        stores_result = supabase_client.table('stores').select('*').execute()
        stores_dict = {s['id']: s for s in (stores_result.data or [])}

        profiles_result = supabase_client.table('profiles').select('*').execute()
        profiles_dict = {p['id']: p for p in (profiles_result.data or [])}

        # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if region:
            evaluations = [e for e in evaluations if stores_dict.get(e.get('store_id'), {}).get('region') == region]

        # CSV ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        import io
        import csv

        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow([
            'è©•ä¾¡ID',
            'åº—èˆ—ã‚³ãƒ¼ãƒ‰',
            'åº—èˆ—å',
            'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³',
            'ãƒ¦ãƒ¼ã‚¶ãƒ¼å',
            'ã‚·ãƒŠãƒªã‚ªID',
            'è³ªå•åŠ›',
            'å‚¾è´åŠ›',
            'ææ¡ˆåŠ›',
            'ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°åŠ›',
            'åˆè¨ˆã‚¹ã‚³ã‚¢',
            'å¹³å‡ã‚¹ã‚³ã‚¢',
            'è©•ä¾¡æ—¥æ™‚'
        ])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for evaluation in evaluations:
            store = stores_dict.get(evaluation.get('store_id'), {})
            user = profiles_dict.get(evaluation.get('user_id'), {})
            scores = evaluation.get('scores', {})

            writer.writerow([
                evaluation.get('id', ''),
                store.get('store_code', ''),
                store.get('store_name', ''),
                store.get('region', ''),
                user.get('display_name', ''),
                evaluation.get('scenario_id', ''),
                scores.get('questioning_skill', 0),
                scores.get('listening_skill', 0),
                scores.get('proposal_skill', 0),
                scores.get('closing_skill', 0),
                evaluation.get('total_score', 0),
                evaluation.get('average_score', 0),
                evaluation.get('created_at', '')
            ])

        # BOMä»˜ãUTF-8ã§è¿”å´ï¼ˆExceläº’æ›ï¼‰
        csv_data = '\ufeff' + output.getvalue()

        return csv_data, 200, {
            'Content-Type': 'text/csv; charset=utf-8',
            'Content-Disposition': f'attachment; filename=evaluations_export_{evaluation.get("created_at", "").split("T")[0] if evaluations else "all"}.csv'
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/admin/export/stores', methods=['GET'])
def export_all_stores():
    """å…¨åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§å‡ºåŠ›ï¼ˆæœ¬éƒ¨ç®¡ç†è€…å°‚ç”¨ï¼‰"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'Database not configured'}), 500

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        region = request.args.get('region')

        # åº—èˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—
        query = supabase_client.table('stores').select('*')

        if region:
            query = query.eq('region', region)

        query = query.order('store_code')
        stores_result = query.execute()
        stores = stores_result.data if stores_result.data else []

        # å„åº—èˆ—ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        for store in stores:
            store_id = store['id']

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
            profiles_result = supabase_client.table('profiles').select('id').eq('store_id', store_id).execute()
            store['user_count'] = len(profiles_result.data) if profiles_result.data else 0

            # ä¼šè©±æ•°
            conversations_result = supabase_client.table('conversations').select('id').eq('store_id', store_id).execute()
            store['conversation_count'] = len(conversations_result.data) if conversations_result.data else 0

            # è©•ä¾¡å¹³å‡ã‚¹ã‚³ã‚¢
            evaluations_result = supabase_client.table('evaluations').select('average_score').eq('store_id', store_id).execute()
            evaluations = evaluations_result.data if evaluations_result.data else []
            store['evaluation_count'] = len(evaluations)
            store['average_score'] = round(sum(e['average_score'] for e in evaluations) / len(evaluations), 2) if evaluations else 0

        # CSV ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        import io
        import csv

        output = io.StringIO()
        writer = csv.writer(output)

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow([
            'åº—èˆ—ã‚³ãƒ¼ãƒ‰',
            'åº—èˆ—å',
            'ãƒªãƒ¼ã‚¸ãƒ§ãƒ³',
            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹',
            'ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°',
            'ä¼šè©±æ•°',
            'è©•ä¾¡æ•°',
            'å¹³å‡ã‚¹ã‚³ã‚¢',
            'ä½œæˆæ—¥'
        ])

        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for store in stores:
            writer.writerow([
                store.get('store_code', ''),
                store.get('store_name', ''),
                store.get('region', ''),
                store.get('status', ''),
                store.get('user_count', 0),
                store.get('conversation_count', 0),
                store.get('evaluation_count', 0),
                store.get('average_score', 0),
                store.get('created_at', '')
            ])

        # BOMä»˜ãUTF-8ã§è¿”å´ï¼ˆExceläº’æ›ï¼‰
        csv_data = '\ufeff' + output.getvalue()

        return csv_data, 200, {
            'Content-Type': 'text/csv; charset=utf-8',
            'Content-Disposition': 'attachment; filename=stores_export.csv'
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# ===== Week 5: è©•ä¾¡ç²¾åº¦æ¤œè¨¼æ©Ÿèƒ½ =====

@app.route('/api/instructor-evaluations', methods=['POST'])
def save_instructor_evaluation():
    """è¬›å¸«è©•ä¾¡ã‚’Supabaseã«ä¿å­˜"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

        data = request.get_json()
        conversation_id = data.get('conversation_id')
        evaluation_id = data.get('evaluation_id')
        user_id = data.get('user_id')
        store_id = data.get('store_id')
        scenario_id = data.get('scenario_id')
        instructor_scores = data.get('instructor_scores')
        instructor_comments = data.get('instructor_comments', {})
        instructor_name = data.get('instructor_name', '')

        if not conversation_id or not evaluation_id or not instructor_scores:
            return jsonify({'success': False, 'error': 'conversation_id, evaluation_id, instructor_scoresã¯å¿…é ˆã§ã™'}), 400

        # AIè©•ä¾¡ã‚’å–å¾—
        ai_eval_result = supabase_client.table('evaluations').select('scores, average_score').eq('id', evaluation_id).execute()
        ai_scores = ai_eval_result.data[0]['scores'] if ai_eval_result.data else {}

        # ã‚¹ã‚³ã‚¢ã®å·®åˆ†ã‚’è¨ˆç®—
        score_differences = {}
        for key in instructor_scores.keys():
            if key in ai_scores:
                score_differences[key] = abs(instructor_scores[key] - ai_scores[key])

        # ç²¾åº¦æŒ‡æ¨™ã‚’è¨ˆç®—
        accuracy_metrics = calculate_accuracy_metrics(instructor_scores, ai_scores)

        # instructor_evaluationsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        result = supabase_client.table('instructor_evaluations').insert({
            'conversation_id': conversation_id,
            'evaluation_id': evaluation_id,
            'user_id': user_id,
            'store_id': store_id,
            'scenario_id': scenario_id,
            'instructor_scores': instructor_scores,
            'instructor_comments': instructor_comments,
            'ai_scores': ai_scores,
            'score_differences': score_differences,
            'accuracy_metrics': accuracy_metrics,
            'instructor_name': instructor_name
        }).execute()

        instructor_evaluation_id = result.data[0]['id'] if result.data else None

        return jsonify({
            'success': True,
            'instructor_evaluation_id': instructor_evaluation_id,
            'score_differences': score_differences,
            'accuracy_metrics': accuracy_metrics
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/instructor-evaluations', methods=['GET'])
def get_instructor_evaluations():
    """è¬›å¸«è©•ä¾¡ã‚’å–å¾—"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

        user_id = request.args.get('user_id')
        scenario_id = request.args.get('scenario_id')
        limit = int(request.args.get('limit', 50))

        query = supabase_client.table('instructor_evaluations').select('*')

        if user_id:
            query = query.eq('user_id', user_id)

        if scenario_id:
            query = query.eq('scenario_id', scenario_id)

        query = query.order('created_at', desc=True).limit(limit)

        result = query.execute()

        return jsonify({
            'success': True,
            'instructor_evaluations': result.data if result.data else []
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/evaluation-accuracy', methods=['GET'])
def get_evaluation_accuracy():
    """è©•ä¾¡ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    try:
        if not supabase_client:
            return jsonify({'success': False, 'error': 'SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500

        scenario_id = request.args.get('scenario_id')
        limit = int(request.args.get('limit', 100))

        query = supabase_client.table('instructor_evaluations').select('*')

        if scenario_id:
            query = query.eq('scenario_id', scenario_id)

        query = query.order('created_at', desc=True).limit(limit)

        result = query.execute()
        instructor_evaluations = result.data if result.data else []

        if not instructor_evaluations:
            return jsonify({
                'success': True,
                'report': {
                    'total_evaluations': 0,
                    'overall_accuracy': 0,
                    'accuracy_by_metric': {},
                    'average_difference': 0,
                    'message': 'è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'
                }
            })

        # å…¨ä½“ã®ç²¾åº¦ã‚’è¨ˆç®—
        total_accuracy = 0
        accuracy_by_metric = {
            'questioning_skill': [],
            'listening_skill': [],
            'proposal_skill': [],
            'closing_skill': []
        }
        total_differences = []

        for evaluation in instructor_evaluations:
            metrics = evaluation.get('accuracy_metrics', {})
            total_accuracy += metrics.get('overall_accuracy', 0)

            # ãƒ¡ãƒˆãƒªãƒƒã‚¯åˆ¥ã®ç²¾åº¦ã‚’åé›†
            for metric in accuracy_by_metric.keys():
                if metric in evaluation.get('score_differences', {}):
                    difference = evaluation['score_differences'][metric]
                    accuracy_by_metric[metric].append(1 - (difference / 5))  # 5ç‚¹æº€ç‚¹ã§ã®ç²¾åº¦
                    total_differences.append(difference)

        # å¹³å‡ç²¾åº¦ã‚’è¨ˆç®—
        overall_accuracy = total_accuracy / len(instructor_evaluations) if instructor_evaluations else 0
        average_difference = sum(total_differences) / len(total_differences) if total_differences else 0

        # ãƒ¡ãƒˆãƒªãƒƒã‚¯åˆ¥ã®å¹³å‡ç²¾åº¦ã‚’è¨ˆç®—
        metric_accuracy = {}
        for metric, accuracies in accuracy_by_metric.items():
            metric_accuracy[metric] = sum(accuracies) / len(accuracies) if accuracies else 0

        report = {
            'total_evaluations': len(instructor_evaluations),
            'overall_accuracy': round(overall_accuracy * 100, 2),
            'accuracy_by_metric': {k: round(v * 100, 2) for k, v in metric_accuracy.items()},
            'average_difference': round(average_difference, 2),
            'scenario_id': scenario_id,
            'evaluations': instructor_evaluations[:10]  # æœ€æ–°10ä»¶ã‚’è¿”ã™
        }

        return jsonify({
            'success': True,
            'report': report
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


def calculate_accuracy_metrics(instructor_scores, ai_scores):
    """ç²¾åº¦æŒ‡æ¨™ã‚’è¨ˆç®—"""
    if not ai_scores:
        return {'overall_accuracy': 0, 'message': 'AIè©•ä¾¡ãŒã‚ã‚Šã¾ã›ã‚“'}

    differences = []
    for key in instructor_scores.keys():
        if key in ai_scores:
            diff = abs(instructor_scores[key] - ai_scores[key])
            differences.append(diff)

    if not differences:
        return {'overall_accuracy': 0, 'message': 'ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒãŒã§ãã¾ã›ã‚“'}

    # å¹³å‡å·®åˆ†ã‚’è¨ˆç®—ï¼ˆ5ç‚¹æº€ç‚¹ï¼‰
    avg_difference = sum(differences) / len(differences)
    # ç²¾åº¦ã‚’è¨ˆç®—ï¼ˆå·®åˆ†ãŒå°ã•ã„ã»ã©ç²¾åº¦ãŒé«˜ã„ï¼‰
    overall_accuracy = 1 - (avg_difference / 5)

    return {
        'overall_accuracy': round(overall_accuracy, 4),
        'average_difference': round(avg_difference, 2),
        'total_comparisons': len(differences)
    }


if __name__ == '__main__':
    import sys
    # ç’°å¢ƒå¤‰æ•°PORTã‚’å„ªå…ˆã€æ¬¡ã«ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã€æœ€å¾Œã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5001
    port = int(os.getenv('PORT', 5001))
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
        except ValueError:
            print("ç„¡åŠ¹ãªãƒãƒ¼ãƒˆç•ªå·ã§ã™ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    print(f"ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­... ãƒãƒ¼ãƒˆ:{port}")
    app.run(debug=False, use_reloader=False, host='0.0.0.0', port=port)
