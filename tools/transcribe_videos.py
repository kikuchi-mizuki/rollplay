#!/usr/bin/env python3
"""
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«ï¼ˆWhisper APIä½¿ç”¨ï¼‰

ä½¿ã„æ–¹:
    python tools/transcribe_videos.py

æ©Ÿèƒ½:
- videos/å†…ã®éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
- Whisper APIã§æ–‡å­—èµ·ã“ã—
- è©±è€…åˆ†é›¢ï¼ˆå–¶æ¥­ãƒ»é¡§å®¢ï¼‰ã®æ¨å®š
- transcripts/ã«JSONå½¢å¼ã§ä¿å­˜
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
BASE_DIR = Path(__file__).parent.parent
VIDEOS_DIR = BASE_DIR / 'videos'
TRANSCRIPTS_DIR = BASE_DIR / 'transcripts'
TRANSCRIPTS_DIR.mkdir(exist_ok=True)

# å¯¾å¿œã™ã‚‹éŸ³å£°/å‹•ç”»å½¢å¼
SUPPORTED_FORMATS = ['.mp3', '.mp4', '.wav', '.m4a', '.webm', '.mpeg', '.mpga']


def transcribe_audio(file_path: Path) -> dict:
    """
    Whisper APIã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æ–‡å­—èµ·ã“ã—çµæœï¼ˆdictï¼‰
    """
    print(f"ğŸ“ æ–‡å­—èµ·ã“ã—é–‹å§‹: {file_path.name}")

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ25MBåˆ¶é™ï¼‰
        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.2f}MB")

        if file_size_mb > 25:
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚åˆ†å‰²ãŒå¿…è¦ã§ã™ã€‚")
            return None

        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        with open(file_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                language="ja"
            )

        print(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {len(transcript.text)}æ–‡å­—")

        return {
            'text': transcript.text,
            'duration': transcript.duration if hasattr(transcript, 'duration') else None,
            'language': transcript.language if hasattr(transcript, 'language') else 'ja',
            'segments': transcript.segments if hasattr(transcript, 'segments') else [],
        }

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def detect_speaker(text: str, previous_speaker: str = None) -> str:
    """
    ç™ºè©±å†…å®¹ã‹ã‚‰è©±è€…ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Args:
        text: ç™ºè©±å†…å®¹
        previous_speaker: å‰ã®è©±è€…

    Returns:
        'sales' ã¾ãŸã¯ 'customer'
    """
    # å–¶æ¥­ã®ç‰¹å¾´çš„ãªãƒ•ãƒ¬ãƒ¼ã‚º
    sales_patterns = [
        'ã”ææ¡ˆ', 'ãŠæ‰‹ä¼ã„', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'ãŠè¦‹ç©',
        'ã”èª¬æ˜', 'ã”æ¡ˆå†…', 'ãŠä¼ºã„', 'ã”è³ªå•', 'ã”ç¢ºèª'
    ]

    # é¡§å®¢ã®ç‰¹å¾´çš„ãªãƒ•ãƒ¬ãƒ¼ã‚º
    customer_patterns = [
        'æ¤œè¨', 'äºˆç®—', 'è²»ç”¨', 'æ‚©ã¿', 'å›°ã£ã¦', 'è€ƒãˆã¦',
        'ä»–ç¤¾', 'æ¯”è¼ƒ', 'ã©ã†ãªã‚“', 'åˆ†ã‹ã‚‰ãªã„'
    ]

    sales_score = sum(1 for pattern in sales_patterns if pattern in text)
    customer_score = sum(1 for pattern in customer_patterns if pattern in text)

    if sales_score > customer_score:
        return 'sales'
    elif customer_score > sales_score:
        return 'customer'
    else:
        # ã‚¹ã‚³ã‚¢ãŒåŒã˜å ´åˆã¯å‰ã®è©±è€…ã¨äº¤äº’ã«
        return 'customer' if previous_speaker == 'sales' else 'sales'


def segment_conversation(transcript_data: dict) -> list:
    """
    æ–‡å­—èµ·ã“ã—çµæœã‚’ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²

    Args:
        transcript_data: Whisper APIã®çµæœ

    Returns:
        ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    segments = []
    previous_speaker = None

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒã‚ã‚‹å ´åˆ
    if transcript_data.get('segments'):
        for seg in transcript_data['segments']:
            text = seg.get('text', '').strip()
            if not text:
                continue

            speaker = detect_speaker(text, previous_speaker)
            previous_speaker = speaker

            segments.append({
                'speaker': 'å–¶æ¥­' if speaker == 'sales' else 'é¡§å®¢',
                'speaker_type': speaker,
                'text': text,
                'start': seg.get('start'),
                'end': seg.get('end'),
            })
    else:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒãªã„å ´åˆã¯å…¨æ–‡ã‚’åˆ†å‰²
        text = transcript_data.get('text', '')
        sentences = text.split('ã€‚')

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            speaker = detect_speaker(sentence, previous_speaker)
            previous_speaker = speaker

            segments.append({
                'speaker': 'å–¶æ¥­' if speaker == 'sales' else 'é¡§å®¢',
                'speaker_type': speaker,
                'text': sentence + 'ã€‚',
            })

    return segments


def process_video_file(video_path: Path) -> bool:
    """
    å‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†

    Args:
        video_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    print(f"\n{'='*60}")
    print(f"å‡¦ç†é–‹å§‹: {video_path.name}")
    print(f"{'='*60}")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    output_filename = video_path.stem + '_transcript.json'
    output_path = TRANSCRIPTS_DIR / output_filename

    # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if output_path.exists():
        print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«æ–‡å­—èµ·ã“ã—æ¸ˆã¿ã§ã™")
        print(f"   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        return True

    # æ–‡å­—èµ·ã“ã—
    transcript_data = transcribe_audio(video_path)
    if not transcript_data:
        return False

    # ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–
    print(f"ğŸ” ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ä¸­...")
    segments = segment_conversation(transcript_data)
    print(f"âœ… {len(segments)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²")

    # çµ±è¨ˆæƒ…å ±
    sales_count = sum(1 for s in segments if s['speaker_type'] == 'sales')
    customer_count = sum(1 for s in segments if s['speaker_type'] == 'customer')
    print(f"   å–¶æ¥­ç™ºè¨€: {sales_count}ä»¶")
    print(f"   é¡§å®¢ç™ºè¨€: {customer_count}ä»¶")

    # çµæœã‚’ä¿å­˜
    result = {
        'source_file': video_path.name,
        'processed_at': datetime.now().isoformat(),
        'duration': transcript_data.get('duration'),
        'language': transcript_data.get('language'),
        'full_text': transcript_data.get('text'),
        'segments': segments,
        'stats': {
            'total_segments': len(segments),
            'sales_segments': sales_count,
            'customer_segments': customer_count,
        }
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_path}")
    return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"""
{'='*60}
éŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ« - Whisper API
{'='*60}
å¯¾å¿œå½¢å¼: {', '.join(SUPPORTED_FORMATS)}
å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {VIDEOS_DIR}
å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {TRANSCRIPTS_DIR}
{'='*60}
    """)

    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    # å‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    video_files = []
    for ext in SUPPORTED_FORMATS:
        video_files.extend(VIDEOS_DIR.glob(f'*{ext}'))

    if not video_files:
        print(f"âš ï¸  {VIDEOS_DIR} ã«éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        sys.exit(0)

    print(f"ğŸ“ {len(video_files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸ:\n")
    for i, vf in enumerate(video_files, 1):
        size_mb = vf.stat().st_size / (1024 * 1024)
        print(f"   {i}. {vf.name} ({size_mb:.2f}MB)")

    print()

    # å‡¦ç†å®Ÿè¡Œ
    success_count = 0
    for video_file in video_files:
        if process_video_file(video_file):
            success_count += 1

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"å‡¦ç†å®Œäº†: {success_count}/{len(video_files)}ä»¶æˆåŠŸ")
    print(f"{'='*60}\n")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    transcripts = list(TRANSCRIPTS_DIR.glob('*.json'))
    if transcripts:
        print(f"ğŸ“„ ç”Ÿæˆã•ã‚ŒãŸæ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«:\n")
        for t in transcripts:
            print(f"   - {t.name}")


if __name__ == '__main__':
    main()
