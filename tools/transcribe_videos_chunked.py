#!/usr/bin/env python3
"""
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«ï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œç‰ˆï¼‰

ä½¿ã„æ–¹:
    python tools/transcribe_videos_chunked.py

æ©Ÿèƒ½:
- videos/å†…ã®éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º
- 25MBè¶…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•åˆ†å‰²
- Whisper APIã§æ–‡å­—èµ·ã“ã—
- è©±è€…åˆ†é›¢ï¼ˆå–¶æ¥­ãƒ»é¡§å®¢ï¼‰ã®æ¨å®š
- transcripts/ã«JSONå½¢å¼ã§ä¿å­˜
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from pydub import AudioSegment

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
BASE_DIR = Path(__file__).parent.parent
VIDEOS_DIR = BASE_DIR / 'videos'
TRANSCRIPTS_DIR = BASE_DIR / 'transcripts'
TEMP_DIR = BASE_DIR / 'temp_chunks'
TRANSCRIPTS_DIR.mkdir(exist_ok=True)
TEMP_DIR.mkdir(exist_ok=True)

# å¯¾å¿œã™ã‚‹éŸ³å£°/å‹•ç”»å½¢å¼
SUPPORTED_FORMATS = ['.mp3', '.mp4', '.wav', '.m4a', '.webm', '.mpeg', '.mpga']

# Whisper APIåˆ¶é™
MAX_FILE_SIZE_MB = 24  # 25MBã§ã¯ãªã24MBã§å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
CHUNK_DURATION_MS = 10 * 60 * 1000  # 10åˆ†ãƒãƒ£ãƒ³ã‚¯


def split_audio(file_path: Path, chunk_duration_ms: int = CHUNK_DURATION_MS) -> list:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        chunk_duration_ms: ãƒãƒ£ãƒ³ã‚¯ã®é•·ã•ï¼ˆãƒŸãƒªç§’ï¼‰

    Returns:
        åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    print(f"ğŸ”ª éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ä¸­...")

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    audio = AudioSegment.from_file(file_path)
    total_duration_ms = len(audio)

    print(f"   ç·æ™‚é–“: {total_duration_ms / 1000 / 60:.2f}åˆ†")

    # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    chunks = []
    chunk_files = []

    for i, start_ms in enumerate(range(0, total_duration_ms, chunk_duration_ms)):
        end_ms = min(start_ms + chunk_duration_ms, total_duration_ms)
        chunk = audio[start_ms:end_ms]

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        chunk_filename = TEMP_DIR / f"{file_path.stem}_chunk_{i:03d}.mp3"
        chunk.export(chunk_filename, format="mp3", bitrate="64k")

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒç¢ºå®Ÿã«æ›¸ãè¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…ã¤
        import time
        time.sleep(0.5)

        if not chunk_filename.exists():
            print(f"âŒ ãƒãƒ£ãƒ³ã‚¯{i+1}ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            continue

        chunk_size_mb = chunk_filename.stat().st_size / (1024 * 1024)
        print(f"   ãƒãƒ£ãƒ³ã‚¯ {i+1}: {chunk_size_mb:.2f}MB ({start_ms/1000:.1f}s - {end_ms/1000:.1f}s)")

        chunk_files.append((chunk_filename, start_ms, end_ms))

    return chunk_files


def transcribe_audio_chunk(file_path: Path, start_ms: int = 0) -> dict:
    """
    éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        start_ms: ãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰

    Returns:
        æ–‡å­—èµ·ã“ã—çµæœï¼ˆdictï¼‰
    """
    try:
        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        with open(file_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                language="ja"
            )

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª¿æ•´
        segments = []
        if hasattr(transcript, 'segments'):
            for seg in transcript.segments:
                segments.append({
                    'text': seg.text,
                    'start': seg.start + (start_ms / 1000),
                    'end': seg.end + (start_ms / 1000),
                })

        return {
            'text': transcript.text,
            'duration': transcript.duration if hasattr(transcript, 'duration') else None,
            'language': transcript.language if hasattr(transcript, 'language') else 'ja',
            'segments': segments,
        }

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def transcribe_large_audio(file_path: Path) -> dict:
    """
    å¤§å®¹é‡éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦æ–‡å­—èµ·ã“ã—

    Args:
        file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æ–‡å­—èµ·ã“ã—çµæœï¼ˆdictï¼‰
    """
    print(f"ğŸ“ æ–‡å­—èµ·ã“ã—é–‹å§‹: {file_path.name}")

    file_size_mb = file_path.stat().st_size / (1024 * 1024)
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.2f}MB")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    if file_size_mb <= MAX_FILE_SIZE_MB:
        # 25MBä»¥ä¸‹ã®å ´åˆã¯ç›´æ¥å‡¦ç†
        print(f"   ç›´æ¥å‡¦ç†ã—ã¾ã™")
        return transcribe_audio_chunk(file_path, 0)

    # 25MBè¶…ã®å ´åˆã¯åˆ†å‰²å‡¦ç†
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ{MAX_FILE_SIZE_MB}MBã‚’è¶…ãˆã¦ã„ã‚‹ãŸã‚ã€åˆ†å‰²å‡¦ç†ã—ã¾ã™")

    chunk_files = split_audio(file_path)
    print(f"âœ… {len(chunk_files)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²å®Œäº†")

    # å„ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—
    all_text = []
    all_segments = []
    total_duration = 0

    for i, (chunk_file, start_ms, end_ms) in enumerate(chunk_files):
        print(f"\nğŸ“ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(chunk_files)} ã‚’æ–‡å­—èµ·ã“ã—ä¸­...")

        chunk_result = transcribe_audio_chunk(chunk_file, start_ms)

        if chunk_result:
            all_text.append(chunk_result['text'])
            if chunk_result.get('segments'):
                all_segments.extend(chunk_result['segments'])
            if chunk_result.get('duration'):
                total_duration += chunk_result['duration']

            print(f"âœ… ãƒãƒ£ãƒ³ã‚¯ {i+1} å®Œäº†: {len(chunk_result['text'])}æ–‡å­—")

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        chunk_file.unlink()

    # çµ±åˆçµæœ
    print(f"\nâœ… å…¨ãƒãƒ£ãƒ³ã‚¯æ–‡å­—èµ·ã“ã—å®Œäº†")
    print(f"   ç·æ–‡å­—æ•°: {sum(len(t) for t in all_text)}æ–‡å­—")

    return {
        'text': '\n'.join(all_text),
        'duration': total_duration,
        'language': 'ja',
        'segments': all_segments,
    }


def detect_speaker(text: str, previous_speaker: str = None) -> str:
    """
    ç™ºè©±å†…å®¹ã‹ã‚‰è©±è€…ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Args:
        text: ç™ºè©±å†…å®¹
        previous_speaker: å‰ã®è©±è€…

    Returns:
        'sales' ã¾ãŸã¯ 'customer'
    """
    # å–¶æ¥­ã®ç‰¹å¾´çš„ãªãƒ•ãƒ¬ãƒ¼ã‚º
    sales_patterns = [
        'ã”ææ¡ˆ', 'ãŠæ‰‹ä¼ã„', 'ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ—ãƒ©ãƒ³', 'ãŠè¦‹ç©',
        'ã”èª¬æ˜', 'ã”æ¡ˆå†…', 'ãŠä¼ºã„', 'ã”è³ªå•', 'ã”ç¢ºèª',
        'ã•ã›ã¦ã„ãŸã ', 'ã„ã‹ãŒã§ã—ã‚‡', 'ã‚ˆã‚ã—ã‘ã‚Œã°'
    ]

    # é¡§å®¢ã®ç‰¹å¾´çš„ãªãƒ•ãƒ¬ãƒ¼ã‚º
    customer_patterns = [
        'æ¤œè¨', 'äºˆç®—', 'è²»ç”¨', 'æ‚©ã¿', 'å›°ã£ã¦', 'è€ƒãˆã¦',
        'ä»–ç¤¾', 'æ¯”è¼ƒ', 'ã©ã†ãªã‚“', 'åˆ†ã‹ã‚‰ãªã„', 'ã§ã™ã­',
        'ãã†ã§ã™ã‹', 'ãªã‚‹ã»ã©'
    ]

    sales_score = sum(1 for pattern in sales_patterns if pattern in text)
    customer_score = sum(1 for pattern in customer_patterns if pattern in text)

    if sales_score > customer_score:
        return 'sales'
    elif customer_score > sales_score:
        return 'customer'
    else:
        # ã‚¹ã‚³ã‚¢ãŒåŒã˜å ´åˆã¯å‰ã®è©±è€…ã¨äº¤äº’ã«
        return 'customer' if previous_speaker == 'sales' else 'sales'


def segment_conversation(transcript_data: dict) -> list:
    """
    æ–‡å­—èµ·ã“ã—çµæœã‚’ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²

    Args:
        transcript_data: Whisper APIã®çµæœ

    Returns:
        ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    segments = []
    previous_speaker = None

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒã‚ã‚‹å ´åˆ
    if transcript_data.get('segments'):
        for seg in transcript_data['segments']:
            text = seg.get('text', '').strip()
            if not text:
                continue

            speaker = detect_speaker(text, previous_speaker)
            previous_speaker = speaker

            segments.append({
                'speaker': 'å–¶æ¥­' if speaker == 'sales' else 'é¡§å®¢',
                'speaker_type': speaker,
                'text': text,
                'start': seg.get('start'),
                'end': seg.get('end'),
            })
    else:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒãªã„å ´åˆã¯å…¨æ–‡ã‚’åˆ†å‰²
        text = transcript_data.get('text', '')
        sentences = text.split('ã€‚')

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            speaker = detect_speaker(sentence, previous_speaker)
            previous_speaker = speaker

            segments.append({
                'speaker': 'å–¶æ¥­' if speaker == 'sales' else 'é¡§å®¢',
                'speaker_type': speaker,
                'text': sentence + 'ã€‚',
            })

    return segments


def process_video_file(video_path: Path) -> bool:
    """
    å‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†

    Args:
        video_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    print(f"\n{'='*60}")
    print(f"å‡¦ç†é–‹å§‹: {video_path.name}")
    print(f"{'='*60}")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    output_filename = video_path.stem + '_transcript.json'
    output_path = TRANSCRIPTS_DIR / output_filename

    # æ—¢ã«å‡¦ç†æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if output_path.exists():
        print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«æ–‡å­—èµ·ã“ã—æ¸ˆã¿ã§ã™")
        print(f"   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        return True

    # æ–‡å­—èµ·ã“ã—
    transcript_data = transcribe_large_audio(video_path)
    if not transcript_data:
        return False

    # ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–
    print(f"ğŸ” ä¼šè©±ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ä¸­...")
    segments = segment_conversation(transcript_data)
    print(f"âœ… {len(segments)}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²")

    # çµ±è¨ˆæƒ…å ±
    sales_count = sum(1 for s in segments if s['speaker_type'] == 'sales')
    customer_count = sum(1 for s in segments if s['speaker_type'] == 'customer')
    print(f"   å–¶æ¥­ç™ºè¨€: {sales_count}ä»¶")
    print(f"   é¡§å®¢ç™ºè¨€: {customer_count}ä»¶")

    # çµæœã‚’ä¿å­˜
    result = {
        'source_file': video_path.name,
        'processed_at': datetime.now().isoformat(),
        'duration': transcript_data.get('duration'),
        'language': transcript_data.get('language'),
        'full_text': transcript_data.get('text'),
        'segments': segments,
        'stats': {
            'total_segments': len(segments),
            'sales_segments': sales_count,
            'customer_segments': customer_count,
        }
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ä¿å­˜å®Œäº†: {output_path}")
    return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print(f"""
{'='*60}
éŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ« - Whisper APIï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
{'='*60}
å¯¾å¿œå½¢å¼: {', '.join(SUPPORTED_FORMATS)}
å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {VIDEOS_DIR}
å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {TRANSCRIPTS_DIR}
æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {MAX_FILE_SIZE_MB}MBï¼ˆè¶…ãˆã‚‹å ´åˆã¯è‡ªå‹•åˆ†å‰²ï¼‰
{'='*60}
    """)

    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    # å‹•ç”»/éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    video_files = []
    for ext in SUPPORTED_FORMATS:
        video_files.extend(VIDEOS_DIR.glob(f'*{ext}'))

    if not video_files:
        print(f"âš ï¸  {VIDEOS_DIR} ã«éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        sys.exit(0)

    print(f"ğŸ“ {len(video_files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸ:\n")
    for i, vf in enumerate(video_files, 1):
        size_mb = vf.stat().st_size / (1024 * 1024)
        status = "è¦åˆ†å‰²" if size_mb > MAX_FILE_SIZE_MB else "ç›´æ¥å‡¦ç†"
        print(f"   {i}. {vf.name} ({size_mb:.2f}MB) [{status}]")

    print()

    # å‡¦ç†å®Ÿè¡Œ
    success_count = 0
    for video_file in video_files:
        try:
            if process_video_file(video_file):
                success_count += 1
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {video_file.name} - {e}")
            continue

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if TEMP_DIR.exists():
        for temp_file in TEMP_DIR.glob('*'):
            temp_file.unlink()

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"å‡¦ç†å®Œäº†: {success_count}/{len(video_files)}ä»¶æˆåŠŸ")
    print(f"{'='*60}\n")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    transcripts = list(TRANSCRIPTS_DIR.glob('*.json'))
    if transcripts:
        print(f"ğŸ“„ ç”Ÿæˆã•ã‚ŒãŸæ–‡å­—èµ·ã“ã—ãƒ•ã‚¡ã‚¤ãƒ«: {len(transcripts)}ä»¶\n")


if __name__ == '__main__':
    main()
